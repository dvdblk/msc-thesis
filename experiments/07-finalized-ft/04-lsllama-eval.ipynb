{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': Value(dtype='int64', id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "Example instance:\t {'SDG': 8, 'ABSTRACT': 'The scheme gives enterprises with business activity in Norway a tax credit on their R&D projects. The R&D content must be approved by the Research Council of Norway ex ante. In 2009, the cap on expenses per enterprise for intramural R&D projects increased to NOK 5.5 million (previously it was N0K 4 million), and NOK11 million (previously it was NOK 8 million) for projects conducted at an R&D institution.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None, '__index_level_0__': 492}\n",
      "id2label: {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17'}\n",
      "label2id: {'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11, '13': 12, '14': 13, '15': 14, '16': 15, '17': 16}\n",
      "Encoded (label2id) label:\t 8\n",
      "Decoded (id2label) label:\t 9\n",
      "17 16 8\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data_natural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929f4c10783846d8927a9412a30d79f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd1cd7e8474472cb3a09f9581a9ef79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336c3be16652404e880a0dfb5a0ad06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1     0.7368    0.8235    0.7778        17\n",
      "       SDG 2     0.9375    0.8824    0.9091        17\n",
      "       SDG 3     0.7500    0.8824    0.8108        17\n",
      "       SDG 4     1.0000    1.0000    1.0000        17\n",
      "       SDG 5     0.7647    0.7647    0.7647        17\n",
      "       SDG 6     0.9412    1.0000    0.9697        16\n",
      "       SDG 7     0.8000    0.7500    0.7742        16\n",
      "       SDG 8     0.7778    0.8235    0.8000        17\n",
      "       SDG 9     0.7059    0.7059    0.7059        17\n",
      "      SDG 10     0.5385    0.4118    0.4667        17\n",
      "      SDG 11     0.8889    0.9412    0.9143        17\n",
      "      SDG 12     0.9231    0.7059    0.8000        17\n",
      "      SDG 13     0.7778    0.8235    0.8000        17\n",
      "      SDG 14     1.0000    1.0000    1.0000        17\n",
      "      SDG 15     0.8125    0.7647    0.7879        17\n",
      "      SDG 16     0.6842    0.7647    0.7222        17\n",
      "      SDG 17     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8118       271\n",
      "   macro avg     0.7670    0.7673    0.7649       271\n",
      "weighted avg     0.8115    0.8118    0.8093       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "LLAMA_PATH = CHECKPOINT_PATH + \"/final/meta-llama/Meta-Llama-3-8B-ft-zo_up/checkpoint-2212\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "llama_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    LLAMA_PATH,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "llama_model.eval()\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data(llama_tokenizer, max_length=1024, padding=\"longest\"), batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# manual evaluation to show classifcation_report\n",
    "true_labels = []\n",
    "logits = []\n",
    "\n",
    "for batch in encoded_dataset[\"test\"]:\n",
    "    batch = {k: v.to(llama_model.device).unsqueeze(0) for k, v in batch.items()}\n",
    "    label = batch.pop(\"label\")\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        out = llama_model(**batch)\n",
    "\n",
    "    true_labels.append(label.item())\n",
    "    logits.extend(out.logits.tolist())\n",
    "\n",
    "probabilites = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "pred_labels = torch.argmax(probabilites, dim=-1).tolist()\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, target_names=[f\"SDG {id2label[i]}\" for i in range(len(labels))], digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9594660401344299, 'eval_accuracy': 0.8081180811808119, 'eval_precision': 0.8060808665957582, 'eval_recall': 0.8081180811808119, 'eval_f1': 0.8050867543472591, 'eval_runtime': 38.1714, 'eval_samples_per_second': 7.1, 'eval_steps_per_second': 1.781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    accuracy = accuracy_score(labels, pred.predictions.argmax(-1))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred.predictions.argmax(-1), average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=llama_model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output\", per_device_eval_batch_size=4),\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "eval_results = eval_trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
