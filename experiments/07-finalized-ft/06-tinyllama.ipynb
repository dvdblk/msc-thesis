{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=thesis\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyLLaMA 1.1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ZO_UP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': Value(dtype='int64', id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "Example instance:\t {'SDG': 8, 'ABSTRACT': 'The scheme gives enterprises with business activity in Norway a tax credit on their R&D projects. The R&D content must be approved by the Research Council of Norway ex ante. In 2009, the cap on expenses per enterprise for intramural R&D projects increased to NOK 5.5 million (previously it was N0K 4 million), and NOK11 million (previously it was NOK 8 million) for projects conducted at an R&D institution.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None, '__index_level_0__': 492}\n",
      "id2label: {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17'}\n",
      "label2id: {'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11, '13': 12, '14': 13, '15': 14, '16': 15, '17': 16}\n",
      "Encoded (label2id) label:\t 8\n",
      "Decoded (id2label) label:\t 9\n",
      "17 16 8\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data_natural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '1',\n",
      " 1: '2',\n",
      " 2: '3',\n",
      " 3: '4',\n",
      " 4: '5',\n",
      " 5: '6',\n",
      " 6: '7',\n",
      " 7: '8',\n",
      " 8: '9',\n",
      " 9: '10',\n",
      " 10: '11',\n",
      " 11: '12',\n",
      " 12: '13',\n",
      " 13: '14',\n",
      " 14: '15',\n",
      " 15: '16',\n",
      " 16: '17'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TinyLlama/TinyLlama_v1.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f499e41fc24a55a281ee40fd147832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afaa6dbbf74418285e72707572659bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.data import DataCollatorWithPadding\n",
    "from transformers.models.llama import LlamaForSequenceClassification\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "MODEL_NAME = \"TinyLlama/TinyLlama_v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    num_labels=len(labels),\n",
    "    token=HF_TOKEN\n",
    ").bfloat16()\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data(tokenizer), batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "METRIC_NAME = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{CHECKPOINT_PATH}/final/{MODEL_NAME}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    #eval_steps=50,\n",
    "    #save_strategy=\"steps\",\n",
    "    #save_steps=50,\n",
    "    #logging_steps=50,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=20,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=METRIC_NAME,\n",
    "    seed=SEED,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    accuracy = accuracy_score(labels, pred.predictions.argmax(-1))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred.predictions.argmax(-1), average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdvdblk\u001b[0m (\u001b[33mngmi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/dbielik/msc-thesis/experiments/04-hf-ft/wandb/run-20240802_055113-pb8mjsev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ngmi/thesis/runs/pb8mjsev' target=\"_blank\">/srv/scratch2/dbielik/.cache/huggingface/checkpoints/final/TinyLlama/TinyLlama_v1.1</a></strong> to <a href='https://wandb.ai/ngmi/thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngmi/thesis' target=\"_blank\">https://wandb.ai/ngmi/thesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngmi/thesis/runs/pb8mjsev' target=\"_blank\">https://wandb.ai/ngmi/thesis/runs/pb8mjsev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1580' max='1580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1580/1580 25:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.860900</td>\n",
       "      <td>2.123789</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.522095</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.435798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.594800</td>\n",
       "      <td>1.941608</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.623450</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.311600</td>\n",
       "      <td>1.564028</td>\n",
       "      <td>0.586716</td>\n",
       "      <td>0.632793</td>\n",
       "      <td>0.586716</td>\n",
       "      <td>0.585080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>1.687745</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.631658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>2.088489</td>\n",
       "      <td>0.682657</td>\n",
       "      <td>0.710766</td>\n",
       "      <td>0.682657</td>\n",
       "      <td>0.681479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>2.324401</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.672825</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.627017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>2.838562</td>\n",
       "      <td>0.671587</td>\n",
       "      <td>0.698412</td>\n",
       "      <td>0.671587</td>\n",
       "      <td>0.663257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>2.921479</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.691118</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.673480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>2.609836</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.721417</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.710621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>2.671516</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.726614</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.624959</td>\n",
       "      <td>0.704797</td>\n",
       "      <td>0.718503</td>\n",
       "      <td>0.704797</td>\n",
       "      <td>0.706001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.636059</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.636318</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.639993</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.638336</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.639676</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.636621</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.637255</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.723599</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.713167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.639042</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.721582</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.709978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.641522</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.721582</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.709978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1580, training_loss=0.3765329193038707, metrics={'train_runtime': 1505.1171, 'train_samples_per_second': 8.371, 'train_steps_per_second': 1.05, 'total_flos': 3.750771032064e+16, 'train_loss': 0.3765329193038707, 'epoch': 20.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.671515703201294,\n",
       " 'eval_accuracy': 0.7121771217712177,\n",
       " 'eval_precision': 0.7266137541642208,\n",
       " 'eval_recall': 0.7121771217712177,\n",
       " 'eval_f1': 0.7136873672333893,\n",
       " 'eval_runtime': 6.017,\n",
       " 'eval_samples_per_second': 45.039,\n",
       " 'eval_steps_per_second': 5.651,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# manual evaluation to show classifcation_report\n",
    "true_labels = []\n",
    "logits = []\n",
    "\n",
    "for batch in encoded_dataset[\"test\"]:\n",
    "    batch = {k: v.to(trainer.args.device).unsqueeze(0) for k, v in batch.items()}\n",
    "    label = batch.pop(\"label\")\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        out = model(**batch)\n",
    "\n",
    "    true_labels.append(label.item())\n",
    "    logits.extend(out.logits.tolist())\n",
    "\n",
    "probabilites = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "pred_labels = torch.argmax(probabilites, dim=-1).tolist()\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, target_names=[f\"SDG {id2label[i]}\" for i in range(len(labels))], digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1     0.8125    0.7647    0.7879        17\n",
      "       SDG 2     0.8000    0.9412    0.8649        17\n",
      "       SDG 3     0.8462    0.6471    0.7333        17\n",
      "       SDG 4     1.0000    0.8824    0.9375        17\n",
      "       SDG 5     0.7333    0.6471    0.6875        17\n",
      "       SDG 6     0.8333    0.9375    0.8824        16\n",
      "       SDG 7     0.9000    0.5625    0.6923        16\n",
      "       SDG 8     0.5000    0.6471    0.5641        17\n",
      "       SDG 9     0.5455    0.7059    0.6154        17\n",
      "      SDG 10     0.5000    0.4118    0.4516        17\n",
      "      SDG 11     0.8750    0.8235    0.8485        17\n",
      "      SDG 12     0.6000    0.5294    0.5625        17\n",
      "      SDG 13     0.6875    0.6471    0.6667        17\n",
      "      SDG 14     0.8824    0.8824    0.8824        17\n",
      "      SDG 15     0.5909    0.7647    0.6667        17\n",
      "      SDG 16     0.5000    0.5882    0.5405        17\n",
      "      SDG 17     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7085       271\n",
      "   macro avg     0.6827    0.6696    0.6696       271\n",
      "weighted avg     0.7217    0.7085    0.7083       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
