{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': Value(dtype='int64', id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "Example instance:\t {'SDG': 8, 'ABSTRACT': 'The scheme gives enterprises with business activity in Norway a tax credit on their R&D projects. The R&D content must be approved by the Research Council of Norway ex ante. In 2009, the cap on expenses per enterprise for intramural R&D projects increased to NOK 5.5 million (previously it was N0K 4 million), and NOK11 million (previously it was NOK 8 million) for projects conducted at an R&D institution.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None, '__index_level_0__': 492}\n",
      "id2label: {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17'}\n",
      "label2id: {'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11, '13': 12, '14': 13, '15': 14, '16': 15, '17': 16}\n",
      "Encoded (label2id) label:\t 8\n",
      "Decoded (id2label) label:\t 9\n",
      "17 16 8\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data_natural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers.models.llama.modeling_llama import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaDecoderLayer,\n",
    "    LlamaConfig,\n",
    "    LlamaRMSNorm,\n",
    "    LlamaModel,\n",
    "    LLAMA_INPUTS_DOCSTRING,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    BaseModelOutputWithPast,\n",
    ")\n",
    "from transformers.cache_utils import Cache, DynamicCache\n",
    "from typing import Optional, List, Union, Tuple\n",
    "\n",
    "\n",
    "class UnmaskingLlamaModel(LlamaModel):\n",
    "    \"\"\"\n",
    "    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`LlamaDecoderLayer`]\n",
    "\n",
    "    Args:\n",
    "        config: LlamaConfig\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: LlamaConfig):\n",
    "        super().__init__(config)\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.embed_tokens = nn.Embedding(\n",
    "            config.vocab_size, config.hidden_size, self.padding_idx\n",
    "        )\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                LlamaDecoderLayer(config, layer_idx)\n",
    "                for layer_idx in range(config.num_hidden_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embed_tokens = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(LLAMA_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPast]:\n",
    "        output_attentions = (\n",
    "            output_attentions\n",
    "            if output_attentions is not None\n",
    "            else self.config.output_attentions\n",
    "        )\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states\n",
    "            if output_hidden_states is not None\n",
    "            else self.config.output_hidden_states\n",
    "        )\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        if (input_ids is None) ^ (inputs_embeds is not None):\n",
    "            raise ValueError(\n",
    "                \"You cannot specify both input_ids and inputs_embeds at the same time, and must specify either one\"\n",
    "            )\n",
    "\n",
    "        if self.gradient_checkpointing and self.training and use_cache:\n",
    "            logger.warning_once(\n",
    "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
    "            )\n",
    "            use_cache = False\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        return_legacy_cache = False\n",
    "        if use_cache and not isinstance(\n",
    "            past_key_values, Cache\n",
    "        ):  # kept for BC (non `Cache` `past_key_values` inputs)\n",
    "            return_legacy_cache = True\n",
    "            past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
    "\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = (\n",
    "                past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            )\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens,\n",
    "                past_seen_tokens + inputs_embeds.shape[1],\n",
    "                device=inputs_embeds.device,\n",
    "            )\n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "        causal_mask = self._update_causal_mask(\n",
    "            attention_mask,\n",
    "            inputs_embeds,\n",
    "            cache_position,\n",
    "            past_key_values,\n",
    "            output_attentions,\n",
    "        )\n",
    "        if causal_mask is not None:\n",
    "            # Assuming causal_mask is a tensor with shape (batch_size, 1, seq_length, hidden_size)\n",
    "            causal_mask_last_row = causal_mask[:, :, -1, :].unsqueeze(2)\n",
    "\n",
    "            # contiguous used to avoid \"RuntimeError: CUDA error: misaligned address\" in some cases\n",
    "            causal_mask = causal_mask_last_row.expand_as(causal_mask).contiguous()\n",
    "            # causal_mask = torch.zeros_like(causal_mask, device=inputs_embeds.device)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # embed positions\n",
    "        hidden_states = inputs_embeds\n",
    "\n",
    "        # decoder layers\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attns = () if output_attentions else None\n",
    "        next_decoder_cache = None\n",
    "\n",
    "        for decoder_layer in self.layers:\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states += (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                layer_outputs = self._gradient_checkpointing_func(\n",
    "                    decoder_layer.__call__,\n",
    "                    hidden_states,\n",
    "                    causal_mask,\n",
    "                    position_ids,\n",
    "                    past_key_values,\n",
    "                    output_attentions,\n",
    "                    use_cache,\n",
    "                    cache_position,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = decoder_layer(\n",
    "                    hidden_states,\n",
    "                    attention_mask=causal_mask,\n",
    "                    position_ids=position_ids,\n",
    "                    past_key_value=past_key_values,\n",
    "                    output_attentions=output_attentions,\n",
    "                    use_cache=use_cache,\n",
    "                    cache_position=cache_position,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if use_cache:\n",
    "                next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
    "\n",
    "            if output_attentions:\n",
    "                all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "        hidden_states = self.norm(hidden_states)\n",
    "\n",
    "        # add hidden states from the last decoder layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        next_cache = next_decoder_cache if use_cache else None\n",
    "        if return_legacy_cache:\n",
    "            next_cache = next_cache.to_legacy_cache()\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [hidden_states, next_cache, all_hidden_states, all_self_attns]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPast(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attns,\n",
    "        )\n",
    "\n",
    "\n",
    "class UnmaskingLlamaForSequenceClassification(LlamaForSequenceClassification):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = UnmaskingLlamaModel(config)\n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f66f2167cc4461b471d1ba8211bf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of UnmaskingLlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eefe8a649a942828c91e0b52899515e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7c604a086841208ee6f17559024b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1     0.7895    0.8824    0.8333        17\n",
      "       SDG 2     0.8333    0.8824    0.8571        17\n",
      "       SDG 3     0.7500    0.8824    0.8108        17\n",
      "       SDG 4     0.9412    0.9412    0.9412        17\n",
      "       SDG 5     0.8125    0.7647    0.7879        17\n",
      "       SDG 6     0.8889    1.0000    0.9412        16\n",
      "       SDG 7     0.6667    0.6250    0.6452        16\n",
      "       SDG 8     0.7857    0.6471    0.7097        17\n",
      "       SDG 9     0.7222    0.7647    0.7429        17\n",
      "      SDG 10     0.5333    0.4706    0.5000        17\n",
      "      SDG 11     0.8824    0.8824    0.8824        17\n",
      "      SDG 12     0.6875    0.6471    0.6667        17\n",
      "      SDG 13     0.8125    0.7647    0.7879        17\n",
      "      SDG 14     1.0000    1.0000    1.0000        17\n",
      "      SDG 15     0.8125    0.7647    0.7879        17\n",
      "      SDG 16     0.5789    0.6471    0.6111        17\n",
      "      SDG 17     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.7823       271\n",
      "   macro avg     0.7351    0.7392    0.7356       271\n",
      "weighted avg     0.7782    0.7823    0.7786       271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "LLAMA_PATH = CHECKPOINT_PATH + \"/final/meta-llama/Meta-Llama-3-8B-ft-zo_up-unmasked/checkpoint-2528/\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "llama_model = UnmaskingLlamaForSequenceClassification.from_pretrained(\n",
    "    LLAMA_PATH,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "llama_model.eval()\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data(llama_tokenizer, max_length=1024, padding=\"longest\"), batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# manual evaluation to show classifcation_report\n",
    "true_labels = []\n",
    "logits = []\n",
    "\n",
    "for batch in encoded_dataset[\"test\"]:\n",
    "    batch = {k: v.to(llama_model.device).unsqueeze(0) for k, v in batch.items()}\n",
    "    label = batch.pop(\"label\")\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        out = llama_model(**batch)\n",
    "\n",
    "    true_labels.append(label.item())\n",
    "    logits.extend(out.logits.tolist())\n",
    "\n",
    "probabilites = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "pred_labels = torch.argmax(probabilites, dim=-1).tolist()\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, target_names=[f\"SDG {id2label[i]}\" for i in range(len(labels))], digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv_final/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdvdblk\u001b[0m (\u001b[33mngmi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/dbielik/msc-thesis/experiments/07-finalized-ft/wandb/run-20240803_151200-wq38k62b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ngmi/huggingface/runs/wq38k62b' target=\"_blank\">./eval_output</a></strong> to <a href='https://wandb.ai/ngmi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngmi/huggingface' target=\"_blank\">https://wandb.ai/ngmi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngmi/huggingface/runs/wq38k62b' target=\"_blank\">https://wandb.ai/ngmi/huggingface/runs/wq38k62b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.389865517616272, 'eval_accuracy': 0.7822878228782287, 'eval_precision': 0.7782114418888549, 'eval_recall': 0.7822878228782287, 'eval_f1': 0.7785993031664066, 'eval_runtime': 38.9459, 'eval_samples_per_second': 6.958, 'eval_steps_per_second': 1.746}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    accuracy = accuracy_score(labels, pred.predictions.argmax(-1))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred.predictions.argmax(-1), average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=llama_model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output\", per_device_eval_batch_size=4),\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "eval_results = eval_trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 14,\n",
       " 14,\n",
       " 8,\n",
       " 4,\n",
       " 11,\n",
       " 0,\n",
       " 3,\n",
       " 14,\n",
       " 8,\n",
       " 2,\n",
       " 13,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 15,\n",
       " 2,\n",
       " 12,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 11,\n",
       " 15,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 13,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 1,\n",
       " 15,\n",
       " 14,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 11,\n",
       " 4,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 15,\n",
       " 12,\n",
       " 6,\n",
       " 0,\n",
       " 13,\n",
       " 11,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 14,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 12,\n",
       " 3,\n",
       " 5,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 10,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 15,\n",
       " 9,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 10,\n",
       " 5,\n",
       " 4,\n",
       " 13,\n",
       " 12,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 1,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 14,\n",
       " 1,\n",
       " 12,\n",
       " 10,\n",
       " 12,\n",
       " 4,\n",
       " 15,\n",
       " 0,\n",
       " 6,\n",
       " 13,\n",
       " 14,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 13,\n",
       " 5,\n",
       " 13,\n",
       " 15,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 2,\n",
       " 13,\n",
       " 6,\n",
       " 11,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 12,\n",
       " 15,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 12,\n",
       " 5,\n",
       " 15,\n",
       " 12,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 15,\n",
       " 7,\n",
       " 15,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 11,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 13,\n",
       " 14,\n",
       " 8,\n",
       " 15,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 4,\n",
       " 10,\n",
       " 12,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 15,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 12,\n",
       " 11,\n",
       " 5,\n",
       " 14,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 1,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 15,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 15,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 14]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
