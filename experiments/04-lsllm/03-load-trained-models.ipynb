{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different ways to load the models\n",
    "\n",
    "the outcome of this jupynb is an easy way to access the finetuned models via variables:\n",
    "* `scibert_model` = SciBERT finetuned on ZO_UP\n",
    "* `llama_model` = LLaMA-3 finetuned on ZO_UP with a classification head\n",
    "* `unllama_model` = LLaMA-3 finetuned on ZO_UP with a classification head without causal mask\n",
    "\n",
    "### Dataset + encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': ClassLabel(names=['1', '10', '11', '12', '13', '14', '15', '16', '17', '2', '3', '4', '5', '6', '7', '8', '9'], id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None)}\n",
      "Example instance:\t {'SDG': 16, 'ABSTRACT': 'The first attempts to modernize simply replaced the single huge engine with a huge electric motor, changing little. The drive-shafts were replaced by wires, the huge steam engine by dozens of small motors. Factories spread out, there was natural light, and room to use ceiling-slung cranes. Workers had responsibility for their own machines, they needed better training and better pay. The electric motor was a wonderful invention, once we changed all the everyday details that surrounded it.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None}\n",
      "Encoded (label2id) label:\t 16\n",
      "Decoded (id2label) label:\t 9\n",
      "9 16 16\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"Is this about poverty?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import datasets\n",
    "import evaluate\n",
    "from evaluate import evaluator, Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class MulticlassAccuracy(Metric):\n",
    "    \"\"\"Workaround for the default Accuracy class which doesn't support passing 'average' to the compute method.\"\"\"\n",
    "\n",
    "    def _info(self):\n",
    "        return evaluate.MetricInfo(\n",
    "            description=\"Accuracy\",\n",
    "            citation=\"\",\n",
    "            inputs_description=\"\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                    \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                }\n",
    "                if self.config_name == \"multilabel\"\n",
    "                else {\n",
    "                    \"predictions\": datasets.Value(\"int32\"),\n",
    "                    \"references\": datasets.Value(\"int32\"),\n",
    "                }\n",
    "            ),\n",
    "            reference_urls=[\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\"],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, normalize=True, sample_weight=None, **kwargs):\n",
    "        # take **kwargs to avoid breaking when the metric is used with a compute method that takes additional arguments\n",
    "        return {\n",
    "            \"accuracy\": float(\n",
    "                accuracy_score(references, predictions, normalize=normalize, sample_weight=sample_weight)\n",
    "            )\n",
    "        }\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "task_evaluator.METRIC_KWARGS = {\"average\": \"weighted\"}\n",
    "metrics_dict = {\n",
    "    \"accuracy\": MulticlassAccuracy(),\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciBERT baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.8610], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "SCIBERT_PATH = CHECKPOINT_PATH + \"/allenai/scibert_scivocab_uncased-ft-zo_up-lower/checkpoint-240/\"\n",
    "\n",
    "scibert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    SCIBERT_PATH,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(\"cuda\")\n",
    "scibert_tokenizer = AutoTokenizer.from_pretrained(SCIBERT_PATH)\n",
    "scibert_model.eval()\n",
    "\n",
    "# Sample input to SciBERT\n",
    "sample_input = scibert_tokenizer(sample_sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "sample_output = scibert_model(**sample_input)\n",
    "print(torch.max(torch.softmax(sample_output.logits, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7269372693726938,\n",
      " 'f1': 0.718275735363878,\n",
      " 'latency_in_seconds': 0.00714278105831949,\n",
      " 'precision': 0.7210623353133084,\n",
      " 'recall': 0.7269372693726938,\n",
      " 'samples_per_second': 140.0014912728228,\n",
      " 'total_time_in_seconds': 1.9356936668045819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SciBERT\n",
    "eval_results = task_evaluator.compute(\n",
    "    scibert_model,\n",
    "    input_column=\"ABSTRACT\",\n",
    "    label_column=\"SDG\",\n",
    "    tokenizer=scibert_tokenizer,\n",
    "    data=dataset[\"test\"],\n",
    "    label_mapping=label2id,\n",
    "    metric=evaluate.combine(metrics_dict)\n",
    ")\n",
    "pprint.pprint(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 4, 9, 14, 15, 1, 5, 5, 10, 11, 12, 15, 14, 14, 10, 0, 14, 4, 1, 7, 1, 6, 11, 7, 10, 1, 1, 9, 9, 2, 14]\n",
      "[3, 9, 4, 9, 14, 15, 16, 5, 5, 12, 11, 12, 1, 4, 14, 10, 0, 13, 4, 1, 7, 15, 6, 11, 7, 10, 1, 15, 9, 9, 2, 10]\n",
      "{'accuracy': 0.7269372693726938,\n",
      " 'f1': 0.718275735363878,\n",
      " 'precision': 0.7210623353133084,\n",
      " 'recall': 0.7269372693726938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Evaluate SciBERT (manual metrics calculation sanity check)\n",
    "scibert_tokenized_dataset = dataset.map(\n",
    "    preprocess_data(scibert_tokenizer, include_labels=False), batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "scibert_tokenized_dataset.set_format(\"torch\")\n",
    "scibert_out_logits = torch.tensor([])\n",
    "for batch in scibert_tokenized_dataset[\"test\"]:\n",
    "    scibert_out_logits = torch.cat(\n",
    "        (\n",
    "            scibert_out_logits,\n",
    "            scibert_model(\n",
    "                input_ids=batch[\"input_ids\"].to(\"cuda\").unsqueeze(0),\n",
    "                attention_mask=batch[\"attention_mask\"].to(\"cuda\").unsqueeze(0)\n",
    "            ).logits.detach().cpu()\n",
    "        )\n",
    "    )\n",
    "\n",
    "#scibert_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"][:64], y_pred=preds_scibert.cpu())\n",
    "_, scibert_preds = torch.max(torch.softmax(scibert_out_logits, dim=-1), dim=-1)\n",
    "scibert_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu())\n",
    "\n",
    "scibert_f1 = f1_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "scibert_precision = precision_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "scibert_recall = recall_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "\n",
    "print(dataset[\"test\"][\"SDG\"][:32])\n",
    "print(scibert_preds[:32].tolist())\n",
    "\n",
    "pprint.pprint({\n",
    "    \"accuracy\": scibert_accuracy,\n",
    "    \"precision\": scibert_precision,\n",
    "    \"recall\": scibert_recall,\n",
    "    \"f1\": scibert_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers.models.llama.modeling_llama import LlamaForSequenceClassification, LlamaDecoderLayer, LlamaConfig, LlamaRMSNorm, LlamaPreTrainedModel, LlamaModel, LLAMA_INPUTS_DOCSTRING, add_start_docstrings_to_model_forward, SequenceClassifierOutputWithPast, BaseModelOutputWithPast, BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.cache_utils import Cache, DynamicCache\n",
    "from typing import Optional, List, Union, Tuple\n",
    "\n",
    "\n",
    "class UnmaskingLlamaModel(LlamaModel):\n",
    "    \"\"\"\n",
    "    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`LlamaDecoderLayer`]\n",
    "\n",
    "    Args:\n",
    "        config: LlamaConfig\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: LlamaConfig):\n",
    "        super().__init__(config)\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
    "        )\n",
    "        self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embed_tokens = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(LLAMA_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPast]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if (input_ids is None) ^ (inputs_embeds is not None):\n",
    "            raise ValueError(\n",
    "                \"You cannot specify both input_ids and inputs_embeds at the same time, and must specify either one\"\n",
    "            )\n",
    "\n",
    "        if self.gradient_checkpointing and self.training and use_cache:\n",
    "            logger.warning_once(\n",
    "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
    "            )\n",
    "            use_cache = False\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        return_legacy_cache = False\n",
    "        if use_cache and not isinstance(past_key_values, Cache):  # kept for BC (non `Cache` `past_key_values` inputs)\n",
    "            return_legacy_cache = True\n",
    "            past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
    "\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "            )\n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "        causal_mask = self._update_causal_mask(\n",
    "            attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
    "        )\n",
    "        if causal_mask is not None:\n",
    "            #print(\"b4\", input_ids.shape, causal_mask.shape, causal_mask)\n",
    "            # Assuming causal_mask is a tensor with shape (batch_size, 1, seq_length, hidden_size)\n",
    "            causal_mask_last_row = causal_mask[:, :, -1, :].unsqueeze(2)\n",
    "            causal_mask = causal_mask_last_row.expand_as(causal_mask)\n",
    "            # causal_mask = torch.zeros_like(causal_mask, device=inputs_embeds.device)\n",
    "\n",
    "            #print(\"after\", causal_mask.shape, causal_mask)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"kek it's none\", causal_mask, input_ids)\n",
    "\n",
    "        # embed positions\n",
    "        hidden_states = inputs_embeds\n",
    "\n",
    "        # decoder layers\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attns = () if output_attentions else None\n",
    "        next_decoder_cache = None\n",
    "\n",
    "        for decoder_layer in self.layers:\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states += (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                layer_outputs = self._gradient_checkpointing_func(\n",
    "                    decoder_layer.__call__,\n",
    "                    hidden_states,\n",
    "                    causal_mask,\n",
    "                    position_ids,\n",
    "                    past_key_values,\n",
    "                    output_attentions,\n",
    "                    use_cache,\n",
    "                    cache_position,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = decoder_layer(\n",
    "                    hidden_states,\n",
    "                    attention_mask=causal_mask,\n",
    "                    position_ids=position_ids,\n",
    "                    past_key_value=past_key_values,\n",
    "                    output_attentions=output_attentions,\n",
    "                    use_cache=use_cache,\n",
    "                    cache_position=cache_position,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if use_cache:\n",
    "                next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
    "\n",
    "            if output_attentions:\n",
    "                all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "        hidden_states = self.norm(hidden_states)\n",
    "\n",
    "        # add hidden states from the last decoder layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        next_cache = next_decoder_cache if use_cache else None\n",
    "        if return_legacy_cache:\n",
    "            next_cache = next_cache.to_legacy_cache()\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_states, next_cache, all_hidden_states, all_self_attns] if v is not None)\n",
    "        return BaseModelOutputWithPast(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attns,\n",
    "        )\n",
    "\n",
    "class UnmaskingLlamaForSequenceClassification(LlamaForSequenceClassification):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = UnmaskingLlamaModel(config)\n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66447281fe1d410aa1da8e6bc5a6db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of UnmaskingLlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "#LLAMA_PATH = \"meta-llama/Meta-Llama-3-8B\"\n",
    "#LLAMA_PATH = f\"{CHECKPOINT_PATH}/meta-llama/Meta-Llama-3-8B-ft-zo_up/checkpoint-2200/\"\n",
    "LLAMA_PATH = f\"{CHECKPOINT_PATH}/meta-llama/Meta-Llama-3-8B-ft-zo_up-unmasked/checkpoint-1850/\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "# llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_model = UnmaskingLlamaForSequenceClassification.from_pretrained(\n",
    "    LLAMA_PATH,\n",
    "    num_labels=17,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "llama_model.eval()\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.8867], dtype=torch.bfloat16),\n",
      "indices=tensor([12]))\n"
     ]
    }
   ],
   "source": [
    "tokenized_sample = llama_tokenizer(sample_sentence, return_tensors=\"pt\")\n",
    "token_ids = tokenized_sample[\"input_ids\"]\n",
    "\n",
    "llama_out = llama_model(token_ids)\n",
    "print(torch.max(torch.softmax(llama_out.logits, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LLaMA - can't use task evaluator because it doesn't support accelerate which is required for inference larger models\n",
    "# https://github.com/huggingface/evaluate/issues/487\n",
    "\n",
    "# tokenize the dataset first\n",
    "llama_tokenized_dataset = dataset.map(\n",
    "    preprocess_data(llama_tokenizer, padding=\"longest\", max_length=1024, include_labels=False), batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "llama_tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# llama_out_logits = torch.tensor([])\n",
    "# for batch in llama_tokenized_dataset[\"test\"]:\n",
    "#     llama_out_logits = torch.cat(\n",
    "#         (\n",
    "#             llama_out_logits,\n",
    "#             llama_model(\n",
    "#                 input_ids=batch[\"input_ids\"].to(\"cuda\").unsqueeze(0),\n",
    "#                 attention_mask=batch[\"attention_mask\"].to(\"cuda\").unsqueeze(0)\n",
    "#             ).logits.detach().cpu()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# need to split the input_ids tensor into two tensors to avoid CUDA out of memory error\n",
    "# out = llama_model(**llama_tokenized_dataset[\"test\"][:128])\n",
    "# out2 = llama_model(**llama_tokenized_dataset[\"test\"][128:])\n",
    "# llama_out_logits = torch.cat((out.logits, out2.logits), dim=0)\n",
    "\n",
    "# Batch size 32 to avoid CUDA out of memory error\n",
    "llama_out_logits = torch.tensor([])\n",
    "batch_size = 64\n",
    "for i in range(0, len(llama_tokenized_dataset[\"test\"]), batch_size):\n",
    "    batch = llama_tokenized_dataset[\"test\"][i:i+batch_size]\n",
    "    out = llama_model(**batch)\n",
    "    llama_out_logits = torch.cat((llama_out_logits, out.logits), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7564575645756457,\n",
      " 'f1': 0.7488491461489248,\n",
      " 'precision': 0.758700999587592,\n",
      " 'recall': 0.7564575645756457}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "llama_pred_probs, llama_preds = torch.max(torch.softmax(llama_out_logits, dim=-1), dim=-1)\n",
    "\n",
    "llama_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds)\n",
    "llama_f1 = f1_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "llama_precision = precision_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "llama_recall = recall_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "\n",
    "pprint.pprint({\n",
    "    \"accuracy\": llama_accuracy,\n",
    "    \"precision\": llama_precision,\n",
    "    \"recall\": llama_recall,\n",
    "    \"f1\": llama_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1       0.71      0.71      0.71        17\n",
      "      SDG 10       0.50      0.41      0.45        17\n",
      "      SDG 11       0.87      0.76      0.81        17\n",
      "      SDG 12       0.53      0.59      0.56        17\n",
      "      SDG 13       0.83      0.88      0.86        17\n",
      "      SDG 14       1.00      1.00      1.00        17\n",
      "      SDG 15       0.84      0.94      0.89        17\n",
      "      SDG 16       0.64      0.53      0.58        17\n",
      "      SDG 17       0.00      0.00      0.00         1\n",
      "       SDG 2       0.72      0.81      0.76        16\n",
      "       SDG 3       0.75      0.88      0.81        17\n",
      "       SDG 4       0.84      0.94      0.89        17\n",
      "       SDG 5       0.74      1.00      0.85        17\n",
      "       SDG 6       0.85      1.00      0.92        17\n",
      "       SDG 7       1.00      0.59      0.74        17\n",
      "       SDG 8       0.53      0.56      0.55        16\n",
      "       SDG 9       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.76       271\n",
      "   macro avg       0.72      0.71      0.71       271\n",
      "weighted avg       0.76      0.76      0.75       271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=dataset[\"test\"][\"SDG\"],\n",
    "    y_pred=llama_preds,\n",
    "    target_names=[f\"SDG {id2label[i]}\" for i in range(len(labels))]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7564575645756457,\n",
       " 'f1': 0.7485577477676632,\n",
       " 'precision': 0.7555064756637431,\n",
       " 'recall': 0.7564575645756457}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama-3\n",
    "{'accuracy': 0.7269372693726938,\n",
    " 'f1': 0.7303868168770821,\n",
    " 'precision': 0.7581306326098612,\n",
    " 'recall': 0.7269372693726938}\n",
    "{'accuracy': 0.7158671586715867,\n",
    " 'f1': 0.7183098469704836,\n",
    " 'precision': 0.7475784117481534,\n",
    " 'recall': 0.7158671586715867}\n",
    "# eval + 128batch:\n",
    "{'accuracy': 0.7195571955719557,\n",
    " 'f1': 0.7218231123589773,\n",
    " 'precision': 0.7505385512396582,\n",
    " 'recall': 0.7195571955719557}\n",
    "# no eval + 128batch:\n",
    "{'accuracy': 0.7269372693726938,\n",
    " 'f1': 0.7303868168770821,\n",
    " 'precision': 0.7581306326098612,\n",
    " 'recall': 0.7269372693726938}\n",
    "\n",
    "# llama-3 unmasked\n",
    "{'accuracy': 0.7564575645756457,\n",
    " 'f1': 0.7485577477676632,\n",
    " 'precision': 0.7555064756637431,\n",
    " 'recall': 0.7564575645756457}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
