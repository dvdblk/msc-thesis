{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIBERT in HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this script to import the variables and settings from ipynb_util.py\n",
    "%run ipynb_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example instance:\t {'ID': 'oai:www.zora.uzh.ch:124422', 'TITLE': 'How sexual selection can drive the evolution of costly sperm ornamentation', 'ABSTRACT': 'Post-copulatory sexual selection (PSS), fuelled by female promiscuity, is credited with the rapid evolution of sperm quality traits across diverse taxa1. Yet, our understanding of the adaptive significance of sperm ornaments and the cryptic female preferences driving their evolution is extremely limited. Here we review the evolutionary allometry of exaggerated sexual traits (for example, antlers, horns, tail feathers, mandibles and dewlaps), show that the giant sperm of some Drosophila species are possibly the most extreme ornaments in all of nature and demonstrate how their existence challenges theories explaining the intensity of sexual selection, mating-system evolution and the fundamental nature of sex differences. We also combine quantitative genetic analyses of interacting sex-specific traits in D. melanogaster with comparative analyses of the condition dependence of male and female reproductive potential across species with varying ornament size to reveal complex dynamics that may underlie sperm-length evolution. Our results suggest that producing few gigantic sperm evolved by (1) Fisherian runaway selection mediated by genetic correlations between sperm length, the female preference for long sperm and female mating frequency, and (2) longer sperm increasing the indirect benefits to females. Our results also suggest that the developmental integration of sperm quality and quantity renders post-copulatory sexual selection on ejaculates unlikely to treat maleâ€“male competition and female choice as discrete processes.', 'URL': 'https://www.zora.uzh.ch/id/eprint/124422', 'SDG': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset\n",
    "# note: if you don't have the data in the folder, use the download-data.sh script\n",
    "dataset = load_dataset(\"json\", data_files=str(DATA_DIR_PATH / \"task1.jsonl\"))\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.3, seed=SEED)\n",
    "\n",
    "example = dataset[\"train\"][0]\n",
    "print(\"Example instance:\\t\", example)\n",
    "\n",
    "labels = set(dataset[\"train\"][\"SDG\"])\n",
    "# identity because labels are already ids and vice-versa\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# base model\n",
    "HF_MODEL_NAME = \"allenai/scibert_scivocab_uncased\"\n",
    "# final model\n",
    "MODEL_NAME = f\"{HF_MODEL_NAME}-ft-task1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)\n",
    "\n",
    "def preprocess_data(instances):\n",
    "    # take a batch of titles and abstracts and concat them\n",
    "    titles = instances[\"TITLE\"]\n",
    "    abstracts = instances[\"ABSTRACT\"]\n",
    "    texts = [f\"{title} {abstract}\" for title, abstract in zip(titles, abstracts)]\n",
    "    # encode\n",
    "    encoding = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # add labels\n",
    "    encoding[\"label\"] = torch.tensor([label2id[label] for label in instances[\"SDG\"]])\n",
    "\n",
    "    return encoding\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example instance:\t {'input_ids': tensor([  102,   539,  5471,  2516,   300,  7021,   111,  2696,   131, 13773,\n",
      "         6619, 21457,  4972,   150,  1422,   579,  1756,  7655,  5471,  2516,\n",
      "          145, 24343,   546,   422,  8086,   810,   214,  3672,  1699,  2432,\n",
      "         7627,   422,   165, 22249,   190,   111,  2857,  2696,   131,  6619,\n",
      "         1671,  7378,  2186,  6555, 12026, 30130,   205,  3481,   422,   580,\n",
      "         2934,   131,   111,  4640,  4150,   131,  6619, 21457, 11874,   137,\n",
      "          111,  8846,   141,  3672,  7637,  7290,   547,  2696,   165,  6343,\n",
      "         2379,   205,  1530,   185,  1579,   111,  6644, 15031, 29868,   131,\n",
      "        24320,   224,  5471,  7378,   145,   168,  1143,   422,  4129, 21480,\n",
      "          422, 13835, 30113,   422,  5533,   588,  5838, 30113,   422, 26510,\n",
      "        30113,   137,   223, 18367,  1970,   546,   422,   405,   198,   111,\n",
      "        15278,  6619,   131,   693, 10760,  1578,   220,  5779,   111,   755,\n",
      "         7424, 21457, 11874,   121,   355,   131,  2540,   137,  3768,   539,\n",
      "          547,  5074,  5212,  7275, 13106,   111,  3165,   131,  5471,  2516,\n",
      "          422, 13234,   579,   429,  2696,   137,   111,  4900,  2540,   131,\n",
      "         2649,  1595,   205,   185,   469,  9548,  4221,  2576,  2519,   131,\n",
      "        10253,  2649,   579,  1154,  7378,   121,   128,   205, 22564,   190,\n",
      "         6935,  2519,   131,   111,   803,  4899,   131,  3398,   137,  3672,\n",
      "         8042,  1411,  2186,  1578,   190,  5543, 21457,  4972,  1243,   147,\n",
      "         2303,  1127,  3277,   198,   552, 21087,  6619,   579,  1755,  2696,\n",
      "          205,   580,   545,  1739,   198,  7428,  2149, 23354, 24744,  6619,\n",
      "        11150,   214,   145,   158,   546,  8534,  1026,  2004, 19691,  2516,\n",
      "         6224,   214,  2576,  5637,   467,  6619,  1755,   422,   111,  3672,\n",
      "         7015,   168,  1113,  6619,   137,  3672, 13234,  1610,   422,   137,\n",
      "          145,   170,   546,  3490,  6619,  1953,   111,  5726,  4376,   147,\n",
      "         5003,   205,   580,   545,   469,  1739,   198,   111,  6391,  3972,\n",
      "          131,  6619,  1671,   137,  6725, 24287,  1422,   579,  1756,  7655,\n",
      "         5471,  2516,   191, 10832,   156,  7056,  8627,   147,   814,  3398,\n",
      "         1159,  3398,  6543,   137,  3672,  3327,   188,  4829,  2125,   205,\n",
      "          103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] how sexual selection can drive the evolution of costly sperm ornamentation post - copulatory sexual selection ( pss ), fuelled by female promiscuity, is credited with the rapid evolution of sperm quality traits across diverse taxa1. yet, our understanding of the adaptive significance of sperm ornaments and the cryptic female preferences driving their evolution is extremely limited. here we review the evolutionary allometry of exaggerated sexual traits ( for example, antlers, horns, tail feathers, mandibles and dewlaps ), show that the giant sperm of some drosophila species are possibly the most extreme ornaments in all of nature and demonstrate how their existence challenges theories explaining the intensity of sexual selection, mating - system evolution and the fundamental nature of sex differences. we also combine quantitative genetic analyses of interacting sex - specific traits in d. melanogaster with comparative analyses of the condition dependence of male and female reproductive potential across species with varying ornament size to reveal complex dynamics that may underlie sperm - length evolution. our results suggest that producing few gigantic sperm evolved by ( 1 ) fisherian runaway selection mediated by genetic correlations between sperm length, the female preference for long sperm and female mating frequency, and ( 2 ) longer sperm increasing the indirect benefits to females. our results also suggest that the developmental integration of sperm quality and quantity renders post - copulatory sexual selection on ejaculates unlikely to treat male â€“ male competition and female choice as discrete processes. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = encoded_dataset[\"train\"][0]\n",
    "print(\"Example instance:\\t\", example)\n",
    "\n",
    "tokenizer.decode(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    HF_MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "METRIC_NAME = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{CHECKPOINT_PATH}/{MODEL_NAME}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    #save_steps=10,\n",
    "    #eval_steps=10,\n",
    "    #logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=20,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=METRIC_NAME,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    accuracy = accuracy_score(labels, pred.predictions.argmax(-1))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred.predictions.argmax(-1), average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='760' max='760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [760/760 09:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.294022</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.121687</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.180433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.983403</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.319233</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.257885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.756778</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.391972</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.384278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.666955</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.415087</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.448823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.752029</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.440522</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.463918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.663559</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.462906</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.482689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.692489</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.527017</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.504697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.768125</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.528349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.789269</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.636693</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.530452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.972066</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.633583</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.546809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.979730</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.626151</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.949719</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.646554</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.548706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.123352</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.610009</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.536982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.074253</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.620763</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.549883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.060297</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.618065</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.544323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.114942</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.625694</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.541881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.131696</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.624919</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.541235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.133356</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.630953</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.543320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.149144</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.630953</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.543320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>2.159063</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.624954</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.541352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=760, training_loss=0.5132972466318231, metrics={'train_runtime': 597.7961, 'train_samples_per_second': 10.07, 'train_steps_per_second': 1.271, 'total_flos': 1584156096552960.0, 'train_loss': 0.5132972466318231, 'epoch': 20.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvdblk/dev/_thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.0742533206939697,\n",
       " 'eval_accuracy': 0.5503875968992248,\n",
       " 'eval_precision': 0.6207630338957288,\n",
       " 'eval_recall': 0.5503875968992248,\n",
       " 'eval_f1': 0.5498825849667871,\n",
       " 'eval_runtime': 4.3855,\n",
       " 'eval_samples_per_second': 29.415,\n",
       " 'eval_steps_per_second': 3.876,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "text = \"This is a test text about climate change.\"\n",
    "\n",
    "MODEL_PATH = f\"{CHECKPOINT_PATH}/{MODEL_NAME}/checkpoint-532\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=len(labels),\n",
    "    id2label={i: label for i, label in enumerate(labels)},\n",
    "    label2id={label: i for i, label in enumerate(labels)}\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model.eval()\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(model.device) for k, v in encoding.items()}\n",
    "\n",
    "outputs = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4732e-03, 8.4256e-04, 1.2375e-03, 1.2201e-03, 1.0317e-03, 1.0760e-03,\n",
      "        1.3087e-03, 1.3920e-03, 2.3354e-03, 7.2098e-04, 6.6897e-04, 8.4898e-04,\n",
      "        8.5957e-04, 9.7841e-01, 1.9451e-03, 1.9424e-03, 1.5772e-03, 1.1073e-03],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "probs = softmax(logits.squeeze().cpu())\n",
    "\n",
    "# for multi-label classification, we need to threshold the probabilities\n",
    "\"\"\"\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "predicted_labels = [id2label(i) for i in np.where(predictions == 1)]\n",
    "print(predicted_labels)\n",
    "\"\"\"\n",
    "# for single-label classification, we can take the argmax\n",
    "print(probs)\n",
    "predictions = probs.argmax(-1)\n",
    "predicted_label = id2label[predictions.int().item()]\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27454/3741609671.py:22: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic(\"reset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def my_reset(*varnames):\n",
    "    \"\"\"\n",
    "    Resets global variables and majority of CUDA memory. Only works in Jupyter.\n",
    "\n",
    "    varnames are what you want to keep\n",
    "    \"\"\"\n",
    "    try:\n",
    "        del model\n",
    "    except NameError:\n",
    "        pass\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.ipc_collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    globals_ = globals()\n",
    "    to_save = {v: globals_[v] for v in varnames}\n",
    "    to_save['my_reset'] = my_reset  # lets keep this function by default\n",
    "    del globals_\n",
    "    get_ipython().magic(\"reset\")\n",
    "    globals().update(to_save)\n",
    "\n",
    "# my_reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating sklearn precision warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9873459873459873, 0.1282051282051282, 0.12816755893678972, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.ones((86, 18)).argmax(-1)\n",
    "p[:10] = torch.Tensor([i for i in range(10)])\n",
    "t = torch.ones(86, dtype=torch.long)\n",
    "t[:18] = torch.Tensor([i for i in range(18)])\n",
    "\n",
    "# no Warning\n",
    "precision_recall_fscore_support(t, p, average=\"weighted\", labels=[i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9748479368732533, 0.12658227848101267, 0.12654518477303286, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning\n",
    "precision_recall_fscore_support(t, p, average=\"weighted\", labels=[i for i in range(11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
