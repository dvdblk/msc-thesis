{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_evaluations(base_dir=\"evals\"):\n",
    "    evaluations = {}\n",
    "    for model in os.listdir(base_dir):\n",
    "        model_path = os.path.join(base_dir, model)\n",
    "        if os.path.isdir(model_path):\n",
    "            evaluations[model] = {}\n",
    "            for file in os.listdir(model_path):\n",
    "                if file.endswith('_evaluation.npy'):\n",
    "                    xai_method = file.split('_')[0]\n",
    "                    file_path = os.path.join(model_path, file)\n",
    "                    evaluations[model][xai_method] = np.load(file_path)\n",
    "    return evaluations\n",
    "\n",
    "# Load all evaluations\n",
    "all_evaluations = load_evaluations()\n",
    "\n",
    "# Compute averages and standard deviations\n",
    "def compute_stats(eval_array):\n",
    "    return np.mean(eval_array, axis=0), np.std(eval_array, axis=0)\n",
    "\n",
    "stats = {model: {xai: compute_stats(eval_array)\n",
    "                 for xai, eval_array in model_evals.items()}\n",
    "         for model, model_evals in all_evaluations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity / correctness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nan(arr):\n",
    "    return np.isnan(arr).any()\n",
    "\n",
    "for model in all_evaluations:\n",
    "    for xai_method in all_evaluations[model]:\n",
    "        # Verify no score is NaN\n",
    "        if has_nan(all_evaluations[model][xai_method]):\n",
    "            print(f\"Model {model} with XAI method {xai_method} has NaNs\")\n",
    "        # check if all values are in the range [-1, 1]\n",
    "        if (all_evaluations[model][xai_method] > 1).any() or (all_evaluations[model][xai_method] < -1).any():\n",
    "            print(f\"Model {model} with XAI method {xai_method} has values outside of [-1, 1]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12377475202083588"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_evaluations[\"llama3\"][\"attnlrp\"][36, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0003,  0.7505, -0.0005, -0.1261, -0.0006, -0.0007,  0.    ,\n",
       "        0.0001, -0.0003, -0.0003, -0.0923, -0.2396, -0.    , -0.006 ,\n",
       "       -0.0123, -0.0039, -0.0061])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_evaluations[\"unllama3\"][\"attnlrp\"][71][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_lrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
