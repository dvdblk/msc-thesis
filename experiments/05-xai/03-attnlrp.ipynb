{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': Value(dtype='int64', id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "Example instance:\t {'SDG': 8, 'ABSTRACT': 'The scheme gives enterprises with business activity in Norway a tax credit on their R&D projects. The R&D content must be approved by the Research Council of Norway ex ante. In 2009, the cap on expenses per enterprise for intramural R&D projects increased to NOK 5.5 million (previously it was N0K 4 million), and NOK11 million (previously it was NOK 8 million) for projects conducted at an R&D institution.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None, '__index_level_0__': 492}\n",
      "id2label: {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '10', 10: '11', 11: '12', 12: '13', 13: '14', 14: '15', 15: '16', 16: '17'}\n",
      "label2id: {'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11, '13': 12, '14': 13, '15': 14, '16': 15, '17': 16}\n",
      "Encoded (label2id) label:\t 8\n",
      "Decoded (id2label) label:\t 9\n",
      "17 16 8\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data_natural.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=6, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def improved_colored_text_plot(tokens, values, model_name):\n",
    "    # Normalize values to range [-1, 1]\n",
    "    max_abs_value = max(abs(min(values)), abs(max(values)))\n",
    "    normalized_values = [v / max_abs_value for v in values]\n",
    "\n",
    "    # Create a custom colormap (blue for negative, white for neutral, red for positive)\n",
    "    colors = ['blue', 'white', 'red']\n",
    "    n_bins = 100\n",
    "    cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 3))\n",
    "    ax.set_xlim(0, len(tokens))\n",
    "    ax.set_ylim(-0.5, 0.5)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Plot colored rectangles and text for each token\n",
    "    for i, (token, value) in enumerate(zip(tokens, normalized_values)):\n",
    "        color = cmap((value + 1) / 2)\n",
    "        rect = Rectangle((i, -0.2), 0.9, 0.4, facecolor=color, edgecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(i + 0.45, 0, token, ha='center', va='center', fontsize=8, rotation=90)\n",
    "\n",
    "    if model_name is not None:\n",
    "        plt.title(\"Relevancy scores for model: \" + model_name)\n",
    "    else:\n",
    "        plt.title('Token Relevancy Visualization')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d71d0a567334ed78649b2b9654b46b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.11.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.11.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.11.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.11.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.12.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.12.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.12.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.12.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.13.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.13.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.13.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.13.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.14.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.14.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.14.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.14.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.15.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.15.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.15.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.15.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.16.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.16.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.16.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.16.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.17.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.17.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.17.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.17.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.18.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.18.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.18.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.18.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.19.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.19.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.19.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.19.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.20.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.20.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.20.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.20.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.21.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.21.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.21.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.21.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.22.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.22.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.22.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.22.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.23.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.23.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.23.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.23.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.24.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.24.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.24.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.24.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.25.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.25.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.25.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.25.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.26.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.26.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.26.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.26.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.27.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.27.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.27.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.27.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.28.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.28.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.28.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.28.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.29.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.29.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.29.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.29.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.30.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.30.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.30.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.30.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.31.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.31.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.31.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for model.layers.31.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/user/dbielik/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:2068: UserWarning: for score.modules_to_save.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== \n",
      "\n",
      "AttnLRP llama rules: LlamaForSequenceClassification(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): lora.Linear(\n",
      "            (base_layer): LinearEpsilon(in_features=4096, out_features=4096, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "          (k_proj): LinearEpsilon(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): lora.Linear(\n",
      "            (base_layer): LinearEpsilon(in_features=4096, out_features=4096, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "          (o_proj): LinearEpsilon(in_features=4096, out_features=4096, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_value_matmul): AttentionValueMatmul()\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): LinearEpsilon(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): LinearEpsilon(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): LinearEpsilon(in_features=11008, out_features=4096, bias=False)\n",
      "          (silu): SiLU()\n",
      "          (proj_silu_mul): ProjSiluMultiplication()\n",
      "        )\n",
      "        (input_layernorm): RMSNormIdentity()\n",
      "        (post_attention_layernorm): RMSNormIdentity()\n",
      "      )\n",
      "    )\n",
      "    (norm): RMSNormIdentity()\n",
      "  )\n",
      "  (score): ModulesToSaveWrapper(\n",
      "    (original_module): LinearEpsilon(in_features=4096, out_features=17, bias=False)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): LinearEpsilon(in_features=4096, out_features=17, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 74.88 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Process 2232719 has 836.00 MiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 162.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m     50\u001b[0m peft_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_attnlrp, model_id\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m---> 51\u001b[0m model_attnlrp \u001b[38;5;241m=\u001b[39m \u001b[43mpeft_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_and_unload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel after AttnLRP rules:\u001b[39m\u001b[38;5;124m\"\u001b[39m, attnlrp\u001b[38;5;241m.\u001b[39mregister(model_attnlrp, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/peft/tuners/lora/model.py:838\u001b[0m, in \u001b[0;36mLoraModel.merge_and_unload\u001b[0;34m(self, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_and_unload\u001b[39m(\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28mself\u001b[39m, progressbar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, safe_merge: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, adapter_names: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m    813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m    This method merges the LoRa layers into the base model. This is needed if someone wants to use the base model\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m    as a standalone model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unload_and_optionally_merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_merge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_merge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_names\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/peft/tuners/lora/model.py:454\u001b[0m, in \u001b[0;36mLoraModel._unload_and_optionally_merge\u001b[0;34m(self, merge, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43monload_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_layer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:61\u001b[0m, in \u001b[0;36monload_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module\u001b[38;5;241m.\u001b[39m_hf_hook, AlignDevicesHook) \u001b[38;5;129;01mand\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39moffload:\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         offloaded_modules\u001b[38;5;241m.\u001b[39mappend(module)\n\u001b[1;32m     64\u001b[0m base_layer_offload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:347\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    340\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    341\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    344\u001b[0m         ):\n\u001b[1;32m    345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 347\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    357\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    358\u001b[0m )\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/utils/modeling.py:400\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 400\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 74.88 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Process 2232719 has 836.00 MiB memory in use. Of the allocated memory 22.31 GiB is allocated by PyTorch, and 162.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\"\"\"load pretrained llama\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.llama.modeling_llama import LlamaForSequenceClassification\n",
    "from lxt.models.llama import (\n",
    "    # LlamaForSequenceClassification,\n",
    "    attnlrp\n",
    ")\n",
    "\n",
    "model_name = f\"{CHECKPOINT_PATH}/final/meta-llama/Llama-2-7b-hf-noq/checkpoint-632\"\n",
    "#model_name = f\"{CHECKPOINT_PATH}/final/meta-llama/Meta-Llama-3-8B-ft-zo_up/checkpoint-2212/\"\n",
    "#model_name = f\"{CHECKPOINT_PATH}/TinyLlama/TinyLlama_v1.1/checkpoint-100/\"\n",
    "#model_name = f\"{CHECKPOINT_PATH}/TinyLlama/TinyLlama_v1.1/checkpoint-80\"\n",
    "#model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# model = LlamaForSequenceClassification.from_pretrained(\n",
    "#     model_name,\n",
    "#     num_labels=17,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     token=HF_TOKEN\n",
    "# )\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# print(\"Model before AttnLRP rules:\", model)\n",
    "\n",
    "# # apply AttnLRP rules\n",
    "# print(\"=\" * 40, \"\\n\")\n",
    "# print(\"Model after AttnLRP rules:\", attnlrp.register(model))\n",
    "\n",
    "\n",
    "# Use AttnLRP LlamaForSequenceClassification model for comparison\n",
    "from lxt.models.llama import LlamaForSequenceClassification as LlamaForSequenceClassificationAttnLRP\n",
    "\n",
    "model_attnlrp = LlamaForSequenceClassificationAttnLRP.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "model_attnlrp.eval()\n",
    "print(\"=\" * 40, \"\\n\")\n",
    "print(\"AttnLRP llama rules:\", model_attnlrp)\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model_attnlrp, model_id=model_name)\n",
    "model_attnlrp = peft_model.merge_and_unload()\n",
    "\n",
    "print(\"=\" * 40, \"\\n\")\n",
    "print(\"Model after AttnLRP rules:\", attnlrp.register(model_attnlrp, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "#sample_sentence = \"This is about clean energy, and also affordable energy.\"\n",
    "sample_sentence = \"In terms of regional shares in the OECD area, OECD Europes share of consumption is slightly higher than the regions share of extraction, while the inverse if tme for the OECD America region. The OECD Asia-Oceania regions share of consumption is the same as its share of extraction. Average income plays a particularly important role. Most of these countries experienced a strong upswing in material extraction starting the early 2000s, although Chinas surge began much earlier. By the early 1990s China had overtaken the United States as the worlds largest extractor of material resources.\"\n",
    "#sample_sentence = \"Ensure access to affordable, reliable, sustainable and modern energy for all\"\n",
    "#sample_sentence = \"Tackling supply deficits within individual catchments will be a high cost approach, increasing the requirement for new infrastructure, and requiring more constraint on water use. However, water is heavy and pumping - and carbon - costs are high, so large scale, long distance transfers are expensive, relative to the waters value. But there is scope for greater interconnection within and between water companies.\"\n",
    "#sample_sentence = \"Is this about clean energy?\"\n",
    "\n",
    "\n",
    "idx = 2\n",
    "sample_sentence = dataset[\"train\"][idx][\"ABSTRACT\"]\n",
    "print(dataset[\"train\"][idx][\"SDG\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [1, 530, 1342, 338, 278, 16162, 11032, 713, 1383, 761, 321, 3944, 973, 393, 17654, 515, 975, 29888, 14424, 310, 15234, 322, 916, 5962, 9427, 29892, 322, 14161, 2705, 3897, 8022, 630, 491, 2181, 504, 815, 273, 322, 2319, 715, 804, 29873, 440, 20657, 9427, 297, 278, 4688, 29871, 29896, 29929, 29929, 29900, 29879, 313, 7675, 29895, 634, 394, 1696, 19454, 278, 9892, 373, 9427, 292, 1951, 29871, 29896, 29929, 29929, 29941, 29892, 278, 321, 3944, 973, 373, 278, 16162, 11032, 713, 1383, 761, 756, 5229, 304, 9792, 304, 967, 4642, 15259, 310, 9427, 29889, 6549, 29892, 1716, 9427, 6358, 322, 10784, 2454, 22786, 800, 1122, 505, 4100, 27721, 363, 278, 15259, 297, 321, 3944, 973, 29879, 29892, 3704, 278, 409, 370, 287, 7881, 15259, 322, 289, 2660, 24974, 313, 29956, 555, 634, 394, 1696, 4525, 28495, 6403, 472, 1023, 11174, 29901, 316, 552, 9446, 9427, 10961, 29879, 22366, 393, 278, 3438, 310, 9138, 322, 4380, 292, 278, 9427, 338, 6133, 393, 372, 4225, 304, 367, 322, 22338, 975, 5030, 5946, 2794, 393, 278, 17407, 23633, 310, 9427, 292, 526, 16317, 666, 630, 2861, 304, 28005, 13258, 358, 322, 13598, 21544, 29889, 450, 13299, 28524, 17407, 6410, 304, 278, 5534, 26504, 975, 278, 1833, 2211, 1602, 3076, 6942, 411, 975, 29888, 14424, 338, 15899, 304, 367, 297, 278, 1797, 310, 3148, 29928, 29871, 29906, 534, 453, 291, 313, 4519, 29949, 29892, 29871, 29906, 29900, 29900, 29929, 29874, 467]\n",
      "Decoded sentence: An example is the Eastern Scotian Shelf ecosystem that suffered from overfishing of cod and other ground fish, and consequently became dominated by crustacean and small planktivorous fish in the early 1990s (Frank et al., Despite the ban on fishing since 1993, the ecosystem on the Eastern Scotian Shelf has failed to recover to its former composition of fish. Thus, both fisheries and climatic perturbations may have important consequences for the composition in ecosystems, including the seabed community composition and biodiversity (Worm et al., These losses occur at two levels: depleted fish stocks imply that the cost of finding and catching the fish is higher that it needs to be and fleet overcapacity means that the economic benefits of fishing are dissipated due to redundant investment and operating costs. The cumulative economic loss to the global economy over the last three decades associated with overfishing is estimated to be in the order of USD 2 trillion (FAO, 2009a).\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sentence\n",
    "tokenized_output = tokenizer(sample_sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "# Extract token IDs\n",
    "token_ids = tokenized_output['input_ids'][0].tolist()\n",
    "\n",
    "# Decode token IDs to readable string\n",
    "decoded_sentence = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"Token IDs:\", token_ids)\n",
    "print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 46.88 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Process 2232719 has 836.00 MiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 116.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      7\u001b[0m     sample_sentence,\n\u001b[1;32m      8\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     11\u001b[0m input_embeds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_input_embeddings()(input_ids)\n\u001b[0;32m---> 13\u001b[0m output_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_logits\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m max_logits, max_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output_logits[\u001b[38;5;241m0\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/models/llama.py:1003\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1003\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1015\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/models/llama.py:750\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    746\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    747\u001b[0m         create_custom_forward(decoder_layer), hidden_states, attention_mask, position_ids\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 750\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/models/llama.py:466\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    464\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    465\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 466\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39madd2(residual, hidden_states)\n\u001b[1;32m    470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/models/llama.py:253\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_silu_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:161\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/hooks.py:347\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    340\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    341\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    344\u001b[0m         ):\n\u001b[1;32m    345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 347\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    357\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    358\u001b[0m )\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/accelerate/utils/modeling.py:400\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 400\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 46.88 MiB is free. Including non-PyTorch memory, this process has 22.81 GiB memory in use. Process 2232719 has 836.00 MiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 116.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from lxt.utils import clean_tokens\n",
    "import lxt.functional as lf\n",
    "\n",
    "model = model_attnlrp\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    sample_sentence,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=True,\n",
    ").input_ids.to(model.device)\n",
    "input_embeds = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "output_logits = model(inputs_embeds=input_embeds.requires_grad_(), use_cache=False).logits\n",
    "print(\"output shape\", output_logits.shape)\n",
    "\n",
    "max_logits, max_indices = torch.max(output_logits[0, :], dim=-1)\n",
    "\n",
    "print(input_embeds.shape)\n",
    "max_logits.backward(max_logits)\n",
    "print(input_embeds.grad.shape)\n",
    "relevance = input_embeds.grad.float().sum(-1).cpu()[0]\n",
    "\n",
    "# normalize relevance between [-1, 1] for plotting\n",
    "relevance = relevance / relevance.abs().max()\n",
    "\n",
    "# remove '_' characters from token strings\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "tokens = clean_tokens(tokens)\n",
    "\n",
    "out = model.config.id2label[max_indices.item()]\n",
    "print(max_indices)\n",
    "print(\"The label of the sequence is: \", out)\n",
    "\n",
    "print(tokens)\n",
    "print(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(relevance)\n",
    "improved_colored_text_plot(tokens, relevance, \"LLaMA-3 8B (quantized to 8bit during training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv_lrp/bin:/home/user/dbielik/.vscode-server/cli/servers/Stable-ea1445cc7016315d0f5728f8e8b12a45dc0a7286/server/bin/remote-cli:/home/user/dbielik/miniconda3/bin:/home/user/dbielik/miniconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/games\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do_lower_case': False, 'unk_token': AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), 'sep_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), 'pad_token': AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), 'cls_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), 'tokenize_chinese_chars': True, 'strip_accents': None, 'clean_up_tokenization_spaces': True, 'do_basic_tokenize': True, 'model_max_length': 1000000000000000019884624838656, 'never_split': None, 'name_or_path': '/srv/scratch2/dbielik/.cache/huggingface/checkpoints/final/allenai/scibert_scivocab_cased-zo_up/checkpoint-432/', 'max_length': 512, 'truncation_side': 'right', 'stride': 0, 'truncation_strategy': 'longest_first', 'pad_token_type_id': 0, 'padding_side': 'right', 'pad_to_multiple_of': None}\n",
      "['[CLS]', 'An', 'example', 'is', 'the', 'Eastern', 'Scot', '##ian', 'She', '##l', '##f', 'ecosystem', 'that', 'suffered', 'from', 'over', '##fish', '##ing', 'of', 'cod', 'and', 'other', 'ground', 'fish', ',', 'and', 'consequently', 'became', 'dominated', 'by', 'crust', '##acea', '##n', 'and', 'small', 'plan', '##kt', '##ivo', '##rous', 'fish', 'in', 'the', 'early', '1990', '##s', '(', 'Frank', 'et', 'al', '.', ',', 'Despite', 'the', 'ban', 'on', 'fishing', 'since', '1993', ',', 'the', 'ecosystem', 'on', 'the', 'Eastern', 'Scot', '##ian', 'She', '##l', '##f', 'has', 'failed', 'to', 'recover', 'to', 'its', 'former', 'composition', 'of', 'fish', '.', 'Thus', ',', 'both', 'fisher', '##ies', 'and', 'climatic', 'perturbations', 'may', 'have', 'important', 'consequences', 'for', 'the', 'composition', 'in', 'ecosystems', ',', 'including', 'the', 'sea', '##bed', 'community', 'composition', 'and', 'biodiversity', '(', 'Wor', '##m', 'et', 'al', '.', ',', 'These', 'losses', 'occur', 'at', 'two', 'levels', ':', 'depleted', 'fish', 'stocks', 'imply', 'that', 'the', 'cost', 'of', 'finding', 'and', 'catch', '##ing', 'the', 'fish', 'is', 'higher', 'that', 'it', 'needs', 'to', 'be', 'and', 'fle', '##et', 'over', '##cap', '##acity', 'means', 'that', 'the', 'economic', 'benefits', 'of', 'fishing', 'are', 'dissip', '##ated', 'due', 'to', 'redundant', 'investment', 'and', 'operating', 'costs', '.', 'The', 'cumulative', 'economic', 'loss', 'to', 'the', 'global', 'economy', 'over', 'the', 'last', 'three', 'decades', 'associated', 'with', 'over', '##fish', '##ing', 'is', 'estimated', 'to', 'be', 'in', 'the', 'order', 'of', 'USD', '2', 'tri', '##ll', '##ion', '(', 'FA', '##O', ',', '2009', '##a', ')', '.', '[SEP]']\n",
      "torch.Size([1, 17])\n",
      "tensor([13], device='cuda:0')\n",
      "The label of the sequence is:  14\n",
      "<class 'list'> ['[CLS]', 'An', 'example', 'is', 'the', 'Eastern', 'Scot', '##ian', 'She', '##l', '##f', 'ecosystem', 'that', 'suffered', 'from', 'over', '##fish', '##ing', 'of', 'cod', 'and', 'other', 'ground', 'fish', ',', 'and', 'consequently', 'became', 'dominated', 'by', 'crust', '##acea', '##n', 'and', 'small', 'plan', '##kt', '##ivo', '##rous', 'fish', 'in', 'the', 'early', '1990', '##s', '(', 'Frank', 'et', 'al', '.', ',', 'Despite', 'the', 'ban', 'on', 'fishing', 'since', '1993', ',', 'the', 'ecosystem', 'on', 'the', 'Eastern', 'Scot', '##ian', 'She', '##l', '##f', 'has', 'failed', 'to', 'recover', 'to', 'its', 'former', 'composition', 'of', 'fish', '.', 'Thus', ',', 'both', 'fisher', '##ies', 'and', 'climatic', 'perturbations', 'may', 'have', 'important', 'consequences', 'for', 'the', 'composition', 'in', 'ecosystems', ',', 'including', 'the', 'sea', '##bed', 'community', 'composition', 'and', 'biodiversity', '(', 'Wor', '##m', 'et', 'al', '.', ',', 'These', 'losses', 'occur', 'at', 'two', 'levels', ':', 'depleted', 'fish', 'stocks', 'imply', 'that', 'the', 'cost', 'of', 'finding', 'and', 'catch', '##ing', 'the', 'fish', 'is', 'higher', 'that', 'it', 'needs', 'to', 'be', 'and', 'fle', '##et', 'over', '##cap', '##acity', 'means', 'that', 'the', 'economic', 'benefits', 'of', 'fishing', 'are', 'dissip', '##ated', 'due', 'to', 'redundant', 'investment', 'and', 'operating', 'costs', '.', 'The', 'cumulative', 'economic', 'loss', 'to', 'the', 'global', 'economy', 'over', 'the', 'last', 'three', 'decades', 'associated', 'with', 'over', '##fish', '##ing', 'is', 'estimated', 'to', 'be', 'in', 'the', 'order', 'of', 'USD', '2', 'tri', '##ll', '##ion', '(', 'FA', '##O', ',', '2009', '##a', ')', '.', '[SEP]']\n",
      "<class 'torch.Tensor'> tensor([     0.046614,     -0.016710,     -0.058135,     -0.001967,\n",
      "             0.022833,      0.028482,      0.005521,      0.004895,\n",
      "             0.009120,     -0.002081,      0.004567,      0.047723,\n",
      "             0.015087,      0.014242,      0.012144,      0.010464,\n",
      "             0.105681,      0.012440,      0.023467,      0.321384,\n",
      "             0.037919,      0.026575,      0.014988,      0.141148,\n",
      "             0.007534,      0.009491,      0.018698,      0.013129,\n",
      "             0.028019,      0.006678,      0.012361,      0.036005,\n",
      "             0.002107,      0.017811,      0.006914,      0.006929,\n",
      "             0.037937,      0.020730,      0.012981,      0.087911,\n",
      "             0.007369,      0.011290,      0.010751,      0.011948,\n",
      "             0.010687,      0.014954,     -0.004644,      0.008024,\n",
      "            -0.019555,     -0.085096,     -0.044840,     -0.001312,\n",
      "             0.000033,      0.012942,      0.015973,      0.325483,\n",
      "             0.018575,      0.004950,      0.018600,      0.015515,\n",
      "             0.028931,      0.006783,      0.034728,      0.034271,\n",
      "             0.005646,      0.011412,      0.013539,      0.002180,\n",
      "             0.005039,      0.029507,      0.008416,      0.010514,\n",
      "             0.006298,      0.005858,      0.029141,      0.004228,\n",
      "             0.001830,      0.013574,      0.128822,      0.117857,\n",
      "             0.036978,      0.012840,      0.026755,      0.327902,\n",
      "             0.031802,      0.007864,      0.017313,      0.005877,\n",
      "             0.006343,      0.009956,      0.021504,      0.025549,\n",
      "             0.003296,      0.019508,      0.005515,      0.003096,\n",
      "             0.055661,      0.012312,      0.013646,      0.017816,\n",
      "             0.366221,      0.012918,      0.063312,      0.011369,\n",
      "             0.031728,      0.083911,     -0.003483,     -0.005813,\n",
      "            -0.003927,     -0.208281,     -0.385176,     -0.956286,\n",
      "            -0.072661,      0.043845,      0.002572,      0.002720,\n",
      "            -0.001327,     -0.005268,      0.004534,     -0.043001,\n",
      "             0.000622,      0.100559,      0.000314,      0.004218,\n",
      "             0.009918,      0.012328,      0.023525,      0.011447,\n",
      "            -0.002616,      0.006007,      0.022955,     -0.000457,\n",
      "             0.012101,      0.115761,      0.011661,      0.011883,\n",
      "             0.004577,      0.006014,      0.009070,      0.007864,\n",
      "             0.004226,      0.011581,      0.010732,      0.001620,\n",
      "             0.002111,     -0.003217,      0.001414,      0.007432,\n",
      "             0.009129,      0.009725,      0.038889,      0.035916,\n",
      "             0.016179,      0.457173,      0.023776,      0.000749,\n",
      "             0.001869,      0.020928,      0.009770,     -0.002134,\n",
      "             0.011823,      0.009382,      0.004871,      0.041540,\n",
      "             0.035267,     -0.005515,      0.004757,      0.008837,\n",
      "            -0.003201,      0.000051,      0.004977,      0.018920,\n",
      "            -0.008329,     -0.002823,     -0.027552,      0.009223,\n",
      "             0.004536,      0.028058,      0.019273,     -0.003585,\n",
      "            -0.005151,      0.295794,      0.030538,     -0.110095,\n",
      "             0.033054,      0.003690,     -0.016831,      0.002585,\n",
      "             0.007057,     -0.005940,      0.000377,      0.020813,\n",
      "             0.001999,      0.004984,      0.012289,      0.001381,\n",
      "             0.049516,     -0.016767,     -0.039797,      0.022307,\n",
      "            -0.007747,      0.000869,     -0.114368,     -1.000000,\n",
      "             0.014419])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Requires `pip install -e ./lxt`\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from lxt.models.bert import attnlrp, BertForSequenceClassification\n",
    "from lxt.utils import pdf_heatmap, clean_tokens\n",
    "\n",
    "def clean_wordpiece_split(tokens):\n",
    "        \"\"\" BERT-specific cleaning. Workaround not working perfect yet.\"\"\"\n",
    "        return [word.replace(\"##\", \"\") for word in tokens]\n",
    "\n",
    "def seq_cls():\n",
    "    \"\"\"AttnLRP for BERT sequence classification task.\"\"\"\n",
    "    SCIBERT_MODEL = CHECKPOINT_PATH + \"/final/allenai/scibert_scivocab_cased-zo_up/checkpoint-432/\"\n",
    "    #SCIBERT_MODEL = CHECKPOINT_PATH + \"/final-nolowercase/allenai/scibert_scivocab_cased-zo_up/checkpoint-640/\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        SCIBERT_MODEL,\n",
    "        do_lower_case=False\n",
    "    )\n",
    "    print(tokenizer.init_kwargs)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        SCIBERT_MODEL,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "    model.eval()\n",
    "\n",
    "    # apply AttnLRP rules\n",
    "    attnlrp.register(model)\n",
    "    tokens = tokenizer(sample_sentence, padding=True, truncation=True, max_length=512, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    print(tokenizer.convert_ids_to_tokens(tokens.input_ids[0]))\n",
    "    input_ids = tokenizer(sample_sentence, return_tensors=\"pt\").input_ids.to(torch.device(\"cuda\"))\n",
    "    inputs_embeds = model.bert.get_input_embeddings()(input_ids)\n",
    "\n",
    "    logits = model(inputs_embeds=inputs_embeds.requires_grad_()).logits\n",
    "    print(logits.shape)\n",
    "\n",
    "    # We explain the sequence label: acceptable or unacceptable\n",
    "    max_logits, max_indices = torch.max(logits, dim=-1)\n",
    "\n",
    "    out = model.config.id2label[max_indices.item()]\n",
    "    print(max_indices)\n",
    "    print(\"The label of the sequence is: \", out)\n",
    "\n",
    "    max_logits.backward(max_logits)\n",
    "\n",
    "    relevance = inputs_embeds.grad.float().sum(-1).cpu()[0]\n",
    "    # normalize relevance between [-1, 1] for plotting\n",
    "    relevance = relevance / relevance.abs().max()\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    tokens = tokens\n",
    "\n",
    "    #pdf_heatmap(tokens, relevance, path=\"./heatmap_seq_cls.pdf\", backend=\"xelatex\")\n",
    "    print(type(tokens), tokens)\n",
    "    print(type(relevance), relevance)\n",
    "\n",
    "    improved_colored_text_plot(tokens, relevance, \"SciBERT\")\n",
    "    #pdf_heatmap(tokens, relevance, path=\"heatmap_seq_cls.pdf\", backend=\"/home/user/dbielik/texlive/bin/x86_64-linux/xelatex\")\n",
    "\n",
    "seq_cls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinBERT attnlrp on Sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-4.712738,  2.973304, -2.078524]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([1, 3])\n",
      "The label of the sequence is:  Bullish\n",
      "['[CLS]', 'citi', 'gives', 'big', 'boost', 'to', 'deere', 'pt', '[SEP]']\n",
      "tensor([-0.044548, -0.045781,  0.033255,  0.185055,  1.000000,  0.007080,\n",
      "        -0.002039,  0.330254, -0.556027])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xelatex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(relevance)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mpdf_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./heatmap_seq_cls.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxelatex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/utils.py:94\u001b[0m, in \u001b[0;36mpdf_heatmap\u001b[0;34m(words, relevances, cmap, path, delete_aux_files, backend)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m relevances\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m relevances\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe relevances must be normalized between -1 and 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m latex_code \u001b[38;5;241m=\u001b[39m _generate_latex(words, relevances, cmap\u001b[38;5;241m=\u001b[39mcmap)\n\u001b[0;32m---> 94\u001b[0m \u001b[43m_compile_latex_to_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatex_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete_aux_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_aux_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/msc-thesis/venv_lrp/lib/python3.12/site-packages/lxt/utils.py:61\u001b[0m, in \u001b[0;36m_compile_latex_to_pdf\u001b[0;34m(latex_code, path, delete_aux_files, backend)\u001b[0m\n\u001b[1;32m     59\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcall([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdflatex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--output-directory\u001b[39m\u001b[38;5;124m'\u001b[39m, path\u001b[38;5;241m.\u001b[39mparent, path\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tex\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxelatex\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxelatex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--output-directory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.tex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF file generated successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delete_aux_files:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/subprocess.py:389\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xelatex'"
     ]
    }
   ],
   "source": [
    "finbert = BertForSequenceClassification.from_pretrained(\n",
    "    \"nickmuchi/finbert-tone-finetuned-fintwitter-classification\",\n",
    "    num_labels=3,\n",
    ").to(\"cuda\")\n",
    "finbert.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"nickmuchi/finbert-tone-finetuned-fintwitter-classification\"\n",
    ")\n",
    "\n",
    "sentence = \"Citi gives big boost to Deere PT\"\n",
    "print(finbert(input_ids=tokenizer(sentence, return_tensors=\"pt\").input_ids.to(\"cuda\")))\n",
    "attnlrp.register(finbert)\n",
    "\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids.to(torch.device(\"cuda\"))\n",
    "inputs_embeds = finbert.bert.get_input_embeddings()(input_ids)\n",
    "\n",
    "logits = finbert(inputs_embeds=inputs_embeds.requires_grad_()).logits\n",
    "print(logits.shape)\n",
    "\n",
    "# We explain the sequence label: acceptable or unacceptable\n",
    "max_logits, max_indices = torch.max(logits, dim=-1)\n",
    "\n",
    "out = finbert.config.id2label[max_indices.item()]\n",
    "print(\"The label of the sequence is: \", out)\n",
    "\n",
    "max_logits.backward(max_logits)\n",
    "\n",
    "relevance = inputs_embeds.grad.float().sum(-1).cpu()[0]\n",
    "# normalize relevance between [-1, 1] for plotting\n",
    "relevance = relevance / relevance.abs().max()\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "tokens = clean_tokens(clean_wordpiece_split(tokens))\n",
    "\n",
    "print(tokens)\n",
    "print(relevance)\n",
    "#pdf_heatmap(tokens, relevance, path=\"./heatmap_seq_cls.pdf\", backend=\"xelatex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
