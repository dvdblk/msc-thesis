{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ipynb_util_tars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different ways to load the models\n",
    "\n",
    "the outcome of this jupynb is an easy way to access the finetuned models via variables:\n",
    "* `scibert_model` = SciBERT finetuned on ZO_UP\n",
    "* `llama_model` = LLaMA-3 finetuned on ZO_UP with a classification head\n",
    "* `unllama_model` = LLaMA-3 finetuned on ZO_UP with a classification head without causal mask\n",
    "\n",
    "### Dataset + encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': ClassLabel(names=['1', '10', '11', '12', '13', '14', '15', '16', '17', '2', '3', '4', '5', '6', '7', '8', '9'], id=None), 'ABSTRACT': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'sdg_desc_short': Value(dtype='string', id=None), 'sdg_desc_long': Value(dtype='string', id=None)}\n",
      "Example instance:\t {'SDG': 16, 'ABSTRACT': 'The first attempts to modernize simply replaced the single huge engine with a huge electric motor, changing little. The drive-shafts were replaced by wires, the huge steam engine by dozens of small motors. Factories spread out, there was natural light, and room to use ceiling-slung cranes. Workers had responsibility for their own machines, they needed better training and better pay. The electric motor was a wonderful invention, once we changed all the everyday details that surrounded it.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None}\n",
      "Encoded (label2id) label:\t 16\n",
      "Decoded (id2label) label:\t 9\n",
      "9 16 16\n"
     ]
    }
   ],
   "source": [
    "%run ../ipynb_load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"Is this about clean energy?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import datasets\n",
    "import evaluate\n",
    "from evaluate import evaluator, Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class MulticlassAccuracy(Metric):\n",
    "    \"\"\"Workaround for the default Accuracy class which doesn't support passing 'average' to the compute method.\"\"\"\n",
    "\n",
    "    def _info(self):\n",
    "        return evaluate.MetricInfo(\n",
    "            description=\"Accuracy\",\n",
    "            citation=\"\",\n",
    "            inputs_description=\"\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                    \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                }\n",
    "                if self.config_name == \"multilabel\"\n",
    "                else {\n",
    "                    \"predictions\": datasets.Value(\"int32\"),\n",
    "                    \"references\": datasets.Value(\"int32\"),\n",
    "                }\n",
    "            ),\n",
    "            reference_urls=[\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\"],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, normalize=True, sample_weight=None, **kwargs):\n",
    "        # take **kwargs to avoid breaking when the metric is used with a compute method that takes additional arguments\n",
    "        return {\n",
    "            \"accuracy\": float(\n",
    "                accuracy_score(references, predictions, normalize=normalize, sample_weight=sample_weight)\n",
    "            )\n",
    "        }\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "task_evaluator.METRIC_KWARGS = {\"average\": \"weighted\"}\n",
    "metrics_dict = {\n",
    "    \"accuracy\": MulticlassAccuracy(),\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciBERT baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.4870], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "SCIBERT_PATH = CHECKPOINT_PATH + \"/allenai/scibert_scivocab_uncased-ft-zo_up-lower/checkpoint-240/\"\n",
    "\n",
    "scibert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    SCIBERT_PATH,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(\"cuda\")\n",
    "scibert_tokenizer = AutoTokenizer.from_pretrained(SCIBERT_PATH)\n",
    "scibert_model.eval()\n",
    "\n",
    "# Sample input to SciBERT\n",
    "sample_input = scibert_tokenizer(sample_sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "sample_output = scibert_model(**sample_input)\n",
    "print(torch.max(torch.softmax(sample_output.logits, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7269372693726938,\n",
      " 'f1': 0.718275735363878,\n",
      " 'latency_in_seconds': 0.006797950022348728,\n",
      " 'precision': 0.7210623353133084,\n",
      " 'recall': 0.7269372693726938,\n",
      " 'samples_per_second': 147.103170325235,\n",
      " 'total_time_in_seconds': 1.8422444560565054}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SciBERT\n",
    "eval_results = task_evaluator.compute(\n",
    "    scibert_model,\n",
    "    input_column=\"ABSTRACT\",\n",
    "    label_column=\"SDG\",\n",
    "    tokenizer=scibert_tokenizer,\n",
    "    data=dataset[\"test\"],\n",
    "    label_mapping=label2id,\n",
    "    metric=evaluate.combine(metrics_dict)\n",
    ")\n",
    "pprint.pprint(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 4, 9, 14, 15, 1, 5, 5, 10, 11, 12, 15, 14, 14, 10, 0, 14, 4, 1, 7, 1, 6, 11, 7, 10, 1, 1, 9, 9, 2, 14]\n",
      "[3, 9, 4, 9, 14, 15, 16, 5, 5, 12, 11, 12, 1, 4, 14, 10, 0, 13, 4, 1, 7, 15, 6, 11, 7, 10, 1, 15, 9, 9, 2, 10]\n",
      "{'accuracy': 0.7269372693726938,\n",
      " 'f1': 0.718275735363878,\n",
      " 'precision': 0.7210623353133084,\n",
      " 'recall': 0.7269372693726938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Evaluate SciBERT (manual metrics calculation sanity check)\n",
    "scibert_tokenized_dataset = dataset.map(\n",
    "    preprocess_data(scibert_tokenizer, include_labels=False), batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "scibert_tokenized_dataset.set_format(\"torch\")\n",
    "scibert_out_logits = torch.tensor([])\n",
    "for batch in scibert_tokenized_dataset[\"test\"]:\n",
    "    scibert_out_logits = torch.cat(\n",
    "        (\n",
    "            scibert_out_logits,\n",
    "            scibert_model(\n",
    "                input_ids=batch[\"input_ids\"].to(\"cuda\").unsqueeze(0),\n",
    "                attention_mask=batch[\"attention_mask\"].to(\"cuda\").unsqueeze(0)\n",
    "            ).logits.detach().cpu()\n",
    "        )\n",
    "    )\n",
    "\n",
    "#scibert_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"][:64], y_pred=preds_scibert.cpu())\n",
    "_, scibert_preds = torch.max(torch.softmax(scibert_out_logits, dim=-1), dim=-1)\n",
    "scibert_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu())\n",
    "\n",
    "scibert_f1 = f1_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "scibert_precision = precision_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "scibert_recall = recall_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=scibert_preds.cpu(), average=\"weighted\")\n",
    "\n",
    "print(dataset[\"test\"][\"SDG\"][:32])\n",
    "print(scibert_preds[:32].tolist())\n",
    "\n",
    "pprint.pprint({\n",
    "    \"accuracy\": scibert_accuracy,\n",
    "    \"precision\": scibert_precision,\n",
    "    \"recall\": scibert_recall,\n",
    "    \"f1\": scibert_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers.models.llama.modeling_llama import LlamaForSequenceClassification, LlamaDecoderLayer, LlamaConfig, LlamaRMSNorm, LlamaPreTrainedModel, LlamaModel, LLAMA_INPUTS_DOCSTRING, add_start_docstrings_to_model_forward, SequenceClassifierOutputWithPast, BaseModelOutputWithPast, BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.cache_utils import Cache, DynamicCache\n",
    "from typing import Optional, List, Union, Tuple\n",
    "\n",
    "\n",
    "class UnmaskingLlamaModel(LlamaModel):\n",
    "    \"\"\"\n",
    "    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`LlamaDecoderLayer`]\n",
    "\n",
    "    Args:\n",
    "        config: LlamaConfig\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: LlamaConfig):\n",
    "        super().__init__(config)\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
    "        )\n",
    "        self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embed_tokens = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(LLAMA_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPast]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if (input_ids is None) ^ (inputs_embeds is not None):\n",
    "            raise ValueError(\n",
    "                \"You cannot specify both input_ids and inputs_embeds at the same time, and must specify either one\"\n",
    "            )\n",
    "\n",
    "        if self.gradient_checkpointing and self.training and use_cache:\n",
    "            logger.warning_once(\n",
    "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
    "            )\n",
    "            use_cache = False\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        return_legacy_cache = False\n",
    "        if use_cache and not isinstance(past_key_values, Cache):  # kept for BC (non `Cache` `past_key_values` inputs)\n",
    "            return_legacy_cache = True\n",
    "            past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
    "\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "            )\n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "        causal_mask = self._update_causal_mask(\n",
    "            attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
    "        )\n",
    "        if causal_mask is not None:\n",
    "            #print(\"b4\", input_ids.shape, causal_mask.shape, causal_mask)\n",
    "            # Assuming causal_mask is a tensor with shape (batch_size, 1, seq_length, hidden_size)\n",
    "            causal_mask_last_row = causal_mask[:, :, -1, :].unsqueeze(2)\n",
    "            causal_mask = causal_mask_last_row.expand_as(causal_mask)\n",
    "            # causal_mask = torch.zeros_like(causal_mask, device=inputs_embeds.device)\n",
    "\n",
    "            #print(\"after\", causal_mask.shape, causal_mask)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"kek it's none\", causal_mask, input_ids)\n",
    "\n",
    "        # embed positions\n",
    "        hidden_states = inputs_embeds\n",
    "\n",
    "        # decoder layers\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attns = () if output_attentions else None\n",
    "        next_decoder_cache = None\n",
    "\n",
    "        for decoder_layer in self.layers:\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states += (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                layer_outputs = self._gradient_checkpointing_func(\n",
    "                    decoder_layer.__call__,\n",
    "                    hidden_states,\n",
    "                    causal_mask,\n",
    "                    position_ids,\n",
    "                    past_key_values,\n",
    "                    output_attentions,\n",
    "                    use_cache,\n",
    "                    cache_position,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = decoder_layer(\n",
    "                    hidden_states,\n",
    "                    attention_mask=causal_mask,\n",
    "                    position_ids=position_ids,\n",
    "                    past_key_value=past_key_values,\n",
    "                    output_attentions=output_attentions,\n",
    "                    use_cache=use_cache,\n",
    "                    cache_position=cache_position,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if use_cache:\n",
    "                next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
    "\n",
    "            if output_attentions:\n",
    "                all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "        hidden_states = self.norm(hidden_states)\n",
    "\n",
    "        # add hidden states from the last decoder layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        next_cache = next_decoder_cache if use_cache else None\n",
    "        if return_legacy_cache:\n",
    "            next_cache = next_cache.to_legacy_cache()\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_states, next_cache, all_hidden_states, all_self_attns] if v is not None)\n",
    "        return BaseModelOutputWithPast(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attns,\n",
    "        )\n",
    "\n",
    "class UnmaskingLlamaForSequenceClassification(LlamaForSequenceClassification):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = UnmaskingLlamaModel(config)\n",
    "        self.score = nn.Linear(config.hidden_size, self.num_labels, bias=False)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fc921173104ad48e00220b3bb8eda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "#LLAMA_PATH = \"meta-llama/Meta-Llama-3-8B\"\n",
    "LLAMA_PATH = f\"{CHECKPOINT_PATH}/meta-llama/Meta-Llama-3-8B-ft-zo_up/checkpoint-2200/\"\n",
    "#LLAMA_PATH = f\"{CHECKPOINT_PATH}/meta-llama/Meta-Llama-3-8B-ft-zo_up-unmasked/checkpoint-1850/\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "# llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    LLAMA_PATH,\n",
    "    num_labels=17,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "llama_model.eval()\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9375], dtype=torch.bfloat16),\n",
      "indices=tensor([14]))\n"
     ]
    }
   ],
   "source": [
    "tokenized_sample = llama_tokenizer(sample_sentence, return_tensors=\"pt\")\n",
    "token_ids = tokenized_sample[\"input_ids\"]\n",
    "\n",
    "llama_out = llama_model(token_ids)\n",
    "print(torch.max(torch.softmax(llama_out.logits, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum 'DatasetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum 'DatasetType'>: __main__.DatasetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LLaMA - can't use task evaluator because it doesn't support accelerate which is required for inference larger models\n",
    "# https://github.com/huggingface/evaluate/issues/487\n",
    "\n",
    "# tokenize the dataset first\n",
    "llama_tokenized_dataset = dataset.map(\n",
    "    preprocess_data(llama_tokenizer, padding=\"longest\", max_length=1024, include_labels=False), batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "llama_tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# llama_out_logits = torch.tensor([])\n",
    "# for batch in llama_tokenized_dataset[\"test\"]:\n",
    "#     llama_out_logits = torch.cat(\n",
    "#         (\n",
    "#             llama_out_logits,\n",
    "#             llama_model(\n",
    "#                 input_ids=batch[\"input_ids\"].to(\"cuda\").unsqueeze(0),\n",
    "#                 attention_mask=batch[\"attention_mask\"].to(\"cuda\").unsqueeze(0)\n",
    "#             ).logits.detach().cpu()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# need to split the input_ids tensor into two tensors to avoid CUDA out of memory error\n",
    "# out = llama_model(**llama_tokenized_dataset[\"test\"][:128])\n",
    "# out2 = llama_model(**llama_tokenized_dataset[\"test\"][128:])\n",
    "# llama_out_logits = torch.cat((out.logits, out2.logits), dim=0)\n",
    "\n",
    "# Batch size 32 to avoid CUDA out of memory error\n",
    "llama_out_logits = torch.tensor([])\n",
    "batch_size = 64\n",
    "for i in range(0, len(llama_tokenized_dataset[\"test\"]), batch_size):\n",
    "    batch = llama_tokenized_dataset[\"test\"][i:i+batch_size]\n",
    "    out = llama_model(**batch)\n",
    "    llama_out_logits = torch.cat((llama_out_logits, out.logits), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7195571955719557,\n",
      " 'f1': 0.7218231123589773,\n",
      " 'precision': 0.7505385512396582,\n",
      " 'recall': 0.7195571955719557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "llama_pred_probs, llama_preds = torch.max(torch.softmax(llama_out_logits, dim=-1), dim=-1)\n",
    "\n",
    "llama_accuracy = accuracy_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds)\n",
    "llama_f1 = f1_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "llama_precision = precision_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "llama_recall = recall_score(y_true=dataset[\"test\"][\"SDG\"], y_pred=llama_preds, average=\"weighted\")\n",
    "\n",
    "pprint.pprint({\n",
    "    \"accuracy\": llama_accuracy,\n",
    "    \"precision\": llama_precision,\n",
    "    \"recall\": llama_recall,\n",
    "    \"f1\": llama_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1       0.71      0.59      0.65        17\n",
      "      SDG 10       0.33      0.59      0.43        17\n",
      "      SDG 11       0.86      0.71      0.77        17\n",
      "      SDG 12       0.48      0.71      0.57        17\n",
      "      SDG 13       0.73      0.94      0.82        17\n",
      "      SDG 14       1.00      0.94      0.97        17\n",
      "      SDG 15       0.88      0.88      0.88        17\n",
      "      SDG 16       0.91      0.59      0.71        17\n",
      "      SDG 17       0.00      0.00      0.00         1\n",
      "       SDG 2       0.87      0.81      0.84        16\n",
      "       SDG 3       0.76      0.76      0.76        17\n",
      "       SDG 4       0.93      0.76      0.84        17\n",
      "       SDG 5       0.80      0.94      0.86        17\n",
      "       SDG 6       0.76      0.94      0.84        17\n",
      "       SDG 7       0.90      0.53      0.67        17\n",
      "       SDG 8       0.54      0.44      0.48        16\n",
      "       SDG 9       0.58      0.41      0.48        17\n",
      "\n",
      "    accuracy                           0.72       271\n",
      "   macro avg       0.71      0.68      0.68       271\n",
      "weighted avg       0.75      0.72      0.72       271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/dbielik/msc-thesis/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    y_true=dataset[\"test\"][\"SDG\"],\n",
    "    y_pred=llama_preds,\n",
    "    target_names=[f\"SDG {id2label[i]}\" for i in range(len(labels))]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7564575645756457,\n",
       " 'f1': 0.7485577477676632,\n",
       " 'precision': 0.7555064756637431,\n",
       " 'recall': 0.7564575645756457}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama-3\n",
    "{'accuracy': 0.7269372693726938,\n",
    " 'f1': 0.7303868168770821,\n",
    " 'precision': 0.7581306326098612,\n",
    " 'recall': 0.7269372693726938}\n",
    "{'accuracy': 0.7158671586715867,\n",
    " 'f1': 0.7183098469704836,\n",
    " 'precision': 0.7475784117481534,\n",
    " 'recall': 0.7158671586715867}\n",
    "# eval + 128batch:\n",
    "{'accuracy': 0.7195571955719557,\n",
    " 'f1': 0.7218231123589773,\n",
    " 'precision': 0.7505385512396582,\n",
    " 'recall': 0.7195571955719557}\n",
    "# no eval + 128batch:\n",
    "{'accuracy': 0.7269372693726938,\n",
    " 'f1': 0.7303868168770821,\n",
    " 'precision': 0.7581306326098612,\n",
    " 'recall': 0.7269372693726938}\n",
    "\n",
    "# llama-3 unmasked\n",
    "{'accuracy': 0.7564575645756457,\n",
    " 'f1': 0.7485577477676632,\n",
    " 'precision': 0.7555064756637431,\n",
    " 'recall': 0.7564575645756457}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9375], dtype=torch.bfloat16),\n",
      "indices=tensor([14]))\n"
     ]
    }
   ],
   "source": [
    "llama_tokenized_sample = llama_tokenizer(\"Is this about clean energy?\", return_tensors=\"pt\")\n",
    "llama_token_ids = llama_tokenized_sample[\"input_ids\"]\n",
    "\n",
    "llama_out = llama_model(llama_token_ids)\n",
    "print(torch.max(torch.softmax(llama_out.logits, dim=-1), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SDG': 3, 'ABSTRACT': 'In terms of regional shares in the OECD area, OECD Europe’s share of consumption is slightly higher than the region’s share of extraction, while the inverse if tme for the OECD America region. The OECD Asia-Oceania region’s share of consumption is the same as its share of extraction. Average income plays a particularly important role. Most of these countries experienced a strong upswing in material extraction starting the early 2000s, although China’s surge began much earlier. By the early 1990s China had overtaken the United States as the world’s largest extractor of material resources.', 'id': None, 'sdg_desc_short': None, 'sdg_desc_long': None}\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"test\"][0])\n",
    "print(llama_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9703, 0.9997, 0.9838, 0.7007, 0.9927, 0.8264, 0.9998, 0.9751,\n",
       "        0.6675, 0.9999, 0.9882, 1.0000, 0.9385, 1.0000, 0.9675, 0.9976, 1.0000,\n",
       "        0.9553, 0.9421, 0.9997, 0.3295, 0.9966, 0.9933, 0.9122, 0.9981, 0.9999,\n",
       "        0.6021, 0.9949, 0.9999, 0.9390, 0.6941, 0.9773, 0.9000, 1.0000, 0.9999,\n",
       "        1.0000, 0.5087, 0.9999, 0.9839, 0.9886, 0.9188, 0.9865, 0.9999, 0.9998,\n",
       "        0.9998, 0.9699, 0.7342, 0.9996, 0.9999, 1.0000, 0.6848, 1.0000, 0.9852,\n",
       "        0.9996, 0.9993, 0.9466, 0.9998, 0.9420, 0.9985, 0.9772, 0.5595, 0.9998,\n",
       "        0.9944, 0.9786, 0.9960, 0.9999, 0.9907, 0.9986, 0.9999, 0.7761, 1.0000,\n",
       "        0.9706, 0.9999, 0.9990, 0.9998, 0.9944, 0.9944, 0.9668, 0.9990, 0.9051,\n",
       "        1.0000, 0.9395, 0.9945, 0.9995, 0.9993, 0.9823, 0.5555, 0.9902, 0.7806,\n",
       "        0.9457, 0.9996, 0.4220, 0.9995, 1.0000, 0.9828, 0.9986, 0.4858, 1.0000,\n",
       "        0.5749, 0.9835, 0.9999, 0.5828, 0.8851, 0.9990, 0.9999, 0.9962, 0.9970,\n",
       "        1.0000, 0.9982, 0.8403, 0.9996, 1.0000, 0.8950, 0.9944, 0.9999, 0.9987,\n",
       "        0.3917, 0.9239, 0.9607, 0.6574, 0.9999, 0.6479, 1.0000, 0.9986, 1.0000,\n",
       "        1.0000, 0.9920, 1.0000, 0.8035, 0.9998, 0.9730, 0.9926, 0.9999, 0.9996,\n",
       "        0.9652, 1.0000, 0.9911, 0.9959, 0.8135, 0.9933, 0.9974, 0.9998, 0.9999,\n",
       "        0.8627, 0.9936, 0.9918, 1.0000, 0.8006, 0.9998, 0.9932, 1.0000, 0.9908,\n",
       "        0.9999, 0.8267, 0.9916, 0.9664, 0.9156, 0.9924, 0.8132, 0.7051, 1.0000,\n",
       "        0.6543, 0.9788, 1.0000, 0.9097, 1.0000, 0.9999, 0.9997, 0.7173, 0.8170,\n",
       "        0.4919, 0.9627, 1.0000, 0.7517, 0.6603, 0.8388, 0.8323, 0.7305, 0.9999,\n",
       "        1.0000, 0.9917, 0.9996, 0.9978, 0.9570, 0.9703, 0.9884, 1.0000, 0.9740,\n",
       "        0.8957, 1.0000, 0.9999, 0.7971, 0.7667, 0.9910, 0.9790, 0.9998, 1.0000,\n",
       "        0.7977, 0.7141, 0.9843, 0.9944, 0.9999, 0.4900, 0.9994, 1.0000, 0.7697,\n",
       "        0.9996, 0.5894, 0.9939, 0.9769, 1.0000, 0.9576, 0.9260, 0.9984, 0.4376,\n",
       "        0.9929, 0.9083, 0.9911, 1.0000, 0.9999, 0.9908, 0.7921, 0.9866, 0.9310,\n",
       "        0.9994, 0.9996, 0.8196, 0.9868, 0.9997, 0.5089, 1.0000, 0.8311, 0.9759,\n",
       "        0.9274, 1.0000, 0.9948, 0.5656, 0.7659, 0.9968, 0.9972, 1.0000, 0.9989,\n",
       "        0.9995, 0.8746, 0.9972, 0.8929, 1.0000, 0.9457, 0.9997, 1.0000, 0.8505,\n",
       "        0.9996, 0.9996, 0.9992, 0.5406, 0.9999, 0.9814, 0.9999, 0.9192, 0.9778,\n",
       "        0.9995, 0.9601, 0.5107, 0.3961, 1.0000, 0.9603, 0.9111, 0.8081, 0.9602,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
